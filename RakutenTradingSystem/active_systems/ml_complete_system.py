"""
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ« - å®Œå…¨çµ±åˆç‰ˆ
- yfinance ãƒ‡ãƒ¼ã‚¿åé›†
- é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆRandomForest, LinearRegression, SimpleMovingAverage, LightGBMï¼‰
- äºˆæ¸¬ç²¾åº¦è©•ä¾¡
- ä¸€æ°—é€šè²«ã§ãƒ¢ãƒ‡ãƒ«ä½œæˆã‹ã‚‰è©•ä¾¡ã¾ã§å®Ÿè¡Œ
"""

import pandas as pd
import numpy as np
import sqlite3
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib
from pathlib import Path
import sys
import os
import warnings
warnings.filterwarnings('ignore')

# yfinanceã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import yfinance as yf
    yfinance_available = True
except ImportError:
    yfinance_available = False

# LightGBMã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import lightgbm as lgb
    lightgbm_available = True
except ImportError:
    lightgbm_available = False

class MLTradingModels:
    """æ©Ÿæ¢°å­¦ç¿’å–å¼•ãƒ¢ãƒ‡ãƒ« - å®Œå…¨çµ±åˆç‰ˆ"""
    
    def __init__(self, db_path: str = "trading_data.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self.feature_columns = None
        self.models = {}
        self.scalers = {}
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.model_dir = Path("models")
        self.model_dir.mkdir(exist_ok=True)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.reports_dir = Path("reports")
        self.reports_dir.mkdir(exist_ok=True)
        
    def collect_yfinance_data(self, symbols: List[str], days: int = 5) -> bool:
        """yfinanceã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        if not yfinance_available:
            self.logger.error("yfinanceãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS chart_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    datetime TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    open_price REAL NOT NULL,
                    high_price REAL NOT NULL,
                    low_price REAL NOT NULL,
                    close_price REAL NOT NULL,
                    volume INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(symbol, datetime, timeframe)
                )
            ''')
            
            success_count = 0
            total_data = 0
            
            for symbol in symbols:
                try:
                    # yfinanceã§ãƒ‡ãƒ¼ã‚¿å–å¾—
                    yahoo_symbol = f"{symbol}.T"
                    end_date = datetime.now()
                    start_date = end_date - timedelta(days=days)
                    
                    ticker = yf.Ticker(yahoo_symbol)
                    data = ticker.history(start=start_date, end=end_date, interval="5m")
                    
                    if data.empty:
                        self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yahoo_symbol}")
                        continue
                    
                    # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
                    df = data.reset_index()
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    for _, row in df.iterrows():
                        cursor.execute('''
                            INSERT OR REPLACE INTO chart_data 
                            (symbol, datetime, timeframe, open_price, high_price, low_price, close_price, volume)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            symbol,
                            row['Datetime'].strftime('%Y-%m-%d %H:%M:%S'),
                            '5M',
                            row['Open'],
                            row['High'],
                            row['Low'],
                            row['Close'],
                            int(row['Volume'])
                        ))
                    
                    success_count += 1
                    total_data += len(df)
                    self.logger.info(f"âœ… {symbol}: {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜")
                    
                except Exception as e:
                    self.logger.error(f"âŒ {symbol}ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {success_count}/{len(symbols)}éŠ˜æŸ„, {total_data}ä»¶")
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """é«˜åº¦ãªç‰¹å¾´é‡ã‚’ä½œæˆ"""
        if df.empty or len(df) < 10:
            return pd.DataFrame()
        
        df = df.copy()
        
        # åŸºæœ¬çš„ãªç‰¹å¾´é‡ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚’é˜²ãï¼‰
        df['price_change'] = df['close_price'].pct_change()
        df['high_low_ratio'] = df['high_price'] / df['low_price'].replace(0, np.nan)
        df['open_close_ratio'] = df['open_price'] / df['close_price'].replace(0, np.nan)
        df['volume_price_ratio'] = df['volume'] / df['close_price'].replace(0, np.nan)
        
        # ç§»å‹•å¹³å‡
        df['sma_5'] = df['close_price'].rolling(window=5).mean()
        df['sma_10'] = df['close_price'].rolling(window=10).mean()
        df['sma_ratio'] = df['close_price'] / df['sma_5'].replace(0, np.nan)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        df['volatility_5'] = df['close_price'].rolling(window=5).std()
        df['volatility_10'] = df['close_price'].rolling(window=10).std()
        
        # å‡ºæ¥é«˜ç³»
        df['volume_sma_5'] = df['volume'].rolling(window=5).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma_5'].replace(0, np.nan)
        
        # RSIï¼ˆç°¡æ˜“ç‰ˆï¼‰
        delta = df['close_price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆéå»ã®å€¤ï¼‰
        for lag in [1, 2, 3, 5]:
            df[f'close_lag_{lag}'] = df['close_price'].shift(lag)
            df[f'volume_lag_{lag}'] = df['volume'].shift(lag)
            df[f'change_lag_{lag}'] = df['price_change'].shift(lag)
        
        # æ™‚é–“ç³»ç‰¹å¾´é‡
        df['hour'] = pd.to_datetime(df['datetime']).dt.hour
        df['minute'] = pd.to_datetime(df['datetime']).dt.minute
        df['time_of_day'] = df['hour'] * 60 + df['minute']
        
        # ç›®æ¨™å¤‰æ•°ï¼ˆæ¬¡ã®æœŸé–“ã®ä¾¡æ ¼ï¼‰
        df['target'] = df['close_price'].shift(-1)
        
        return df
    
    def prepare_data(self, symbol: str, period: int = 1000) -> tuple:
        """ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
        self.logger.info(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­: {symbol}")
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            # yfinanceãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            query = '''
                SELECT datetime, open_price, high_price, low_price, close_price, volume
                FROM chart_data
                WHERE symbol = ? AND timeframe = '5M'
                ORDER BY datetime DESC
                LIMIT ?
            '''
            
            df = pd.read_sql_query(query, conn, params=(symbol, period))
            conn.close()
            
            if df.empty:
                self.logger.error(f"âŒ {symbol} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None, None, None, None
            
            self.logger.info(f"å–å¾—ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã³æ›¿ãˆ
            df = df.sort_values('datetime').reset_index(drop=True)
            
            # ç‰¹å¾´é‡ã‚’ä½œæˆ
            df = self.create_features(df)
            
            # ç‰¹å¾´é‡ã®åˆ—ã‚’å®šç¾©
            feature_cols = [
                'price_change', 'high_low_ratio', 'open_close_ratio', 'volume_price_ratio',
                'sma_ratio', 'volatility_5', 'volatility_10', 'volume_ratio', 'rsi',
                'close_lag_1', 'close_lag_2', 'close_lag_3', 'close_lag_5',
                'volume_lag_1', 'volume_lag_2', 'volume_lag_3', 'volume_lag_5',
                'change_lag_1', 'change_lag_2', 'change_lag_3', 'change_lag_5',
                'hour', 'minute', 'time_of_day'
            ]
            
            # æ¬ æå€¤ã‚’å‰Šé™¤
            df = df.dropna()
            
            if len(df) < 50:
                self.logger.error(f"âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({len(df)}ä»¶)")
                return None, None, None, None
            
            # ç‰¹å¾´é‡ã¨ç›®æ¨™å¤‰æ•°ã‚’åˆ†é›¢
            X = df[feature_cols].copy()
            y = df['target'].copy()
            
            # NaNã‚„ç„¡é™å¤§ã®å€¤ã‚’å‡¦ç†
            X = X.replace([np.inf, -np.inf], np.nan)
            X = X.fillna(X.median())
            
            # ã•ã‚‰ã«ç„¡é™å¤§ã‚„ç•°å¸¸å€¤ã‚’ã‚¯ãƒªãƒƒãƒ—
            X = X.clip(-1e6, 1e6)
            
            self.logger.info(f"ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
            self.logger.info(f"æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
            
            self.feature_columns = feature_cols
            
            return X, y, df, feature_cols
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, None, None
    
    def compare_models(self, X, y):
        """è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒ"""
        results = {}
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=False
        )
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # 1. Random Forest
        self.logger.info("Random Forest ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_model.fit(X_train_scaled, y_train)
        rf_pred = rf_model.predict(X_test_scaled)
        
        results['RandomForest'] = {
            'mse': mean_squared_error(y_test, rf_pred),
            'mae': mean_absolute_error(y_test, rf_pred),
            'r2': r2_score(y_test, rf_pred),
            'predictions': rf_pred,
            'model': rf_model
        }
        
        # 2. Linear Regression
        self.logger.info("Linear Regression ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        lr_model = LinearRegression()
        lr_model.fit(X_train_scaled, y_train)
        lr_pred = lr_model.predict(X_test_scaled)
        
        results['LinearRegression'] = {
            'mse': mean_squared_error(y_test, lr_pred),
            'mae': mean_absolute_error(y_test, lr_pred),
            'r2': r2_score(y_test, lr_pred),
            'predictions': lr_pred,
            'model': lr_model
        }
        
        # 3. Simple Moving Average
        self.logger.info("Simple Moving Average ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
        window = 5
        sma_pred = []
        for i in range(window, len(y_test) + window):
            if i - window < len(y_train):
                pred = np.mean(y_train.iloc[max(0, i-window):i])
                sma_pred.append(pred)
        
        # é•·ã•ã‚’èª¿æ•´
        sma_pred = np.array(sma_pred[:len(y_test)])
        if len(sma_pred) < len(y_test):
            # ä¸è¶³åˆ†ã‚’æœ€å¾Œã®å€¤ã§åŸ‹ã‚ã‚‹
            last_val = sma_pred[-1] if len(sma_pred) > 0 else np.mean(y_train)
            sma_pred = np.concatenate([sma_pred, np.full(len(y_test) - len(sma_pred), last_val)])
        
        results['SimpleMovingAverage'] = {
            'mse': mean_squared_error(y_test, sma_pred),
            'mae': mean_absolute_error(y_test, sma_pred),
            'r2': r2_score(y_test, sma_pred),
            'predictions': sma_pred,
            'model': None
        }
        
        # 4. LightGBM (åˆ©ç”¨å¯èƒ½ãªå ´åˆ)
        if lightgbm_available:
            try:
                self.logger.info("LightGBM ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ä¸­...")
                lgb_model = lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)
                lgb_model.fit(X_train, y_train)
                lgb_pred = lgb_model.predict(X_test)
                
                results['LightGBM'] = {
                    'mse': mean_squared_error(y_test, lgb_pred),
                    'mae': mean_absolute_error(y_test, lgb_pred),
                    'r2': r2_score(y_test, lgb_pred),
                    'predictions': lgb_pred,
                    'model': lgb_model
                }
            except Exception as e:
                self.logger.warning(f"LightGBMè¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜
        self.scalers['scaler'] = scaler
        
        return results, y_test
    
    def generate_comparison_report(self, symbol: str, results: dict, y_test: np.ndarray) -> str:
        """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = f"=== {symbol} ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ ===\n\n"
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’æ•´ç†
        model_scores = []
        for model_name, metrics in results.items():
            model_scores.append({
                'model': model_name,
                'mse': metrics['mse'],
                'mae': metrics['mae'],
                'r2': metrics['r2']
            })
        
        # MAEã§ä¸¦ã³æ›¿ãˆï¼ˆä½ã„ã»ã†ãŒè‰¯ã„ï¼‰
        model_scores.sort(key=lambda x: x['mae'])
        
        report += "ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒï¼ˆMAEé †ï¼‰:\n"
        for i, score in enumerate(model_scores, 1):
            report += f"{i}. {score['model']}\n"
            report += f"   MSE: {score['mse']:.4f}\n"
            report += f"   MAE: {score['mae']:.4f}\n"
            report += f"   RÂ²: {score['r2']:.4f}\n\n"
        
        # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«
        best_model = model_scores[0]
        report += f"ğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_model['model']}\n"
        report += f"   ç²¾åº¦è©•ä¾¡: {'é«˜ç²¾åº¦' if best_model['mae'] < 10 else 'ä¸­ç²¾åº¦' if best_model['mae'] < 50 else 'ä½ç²¾åº¦'}\n\n"
        
        # LightGBMã®çµæœãŒã‚ã‚Œã°ç‰¹åˆ¥ã«è¨˜è¼‰
        if 'LightGBM' in results:
            lgb_metrics = results['LightGBM']
            lgb_rank = next(i for i, score in enumerate(model_scores, 1) if score['model'] == 'LightGBM')
            report += f"ğŸš€ LightGBMæ€§èƒ½ï¼ˆ{lgb_rank}ä½ï¼‰:\n"
            report += f"   MSE: {lgb_metrics['mse']:.4f}\n"
            report += f"   MAE: {lgb_metrics['mae']:.4f}\n"
            report += f"   RÂ²: {lgb_metrics['r2']:.4f}\n\n"
        
        # ç¾åœ¨ä¾¡æ ¼ã¨äºˆæ¸¬
        try:
            conn = sqlite3.connect(self.db_path)
            query = '''
                SELECT close_price FROM chart_data
                WHERE symbol = ? AND timeframe = '5M'
                ORDER BY datetime DESC LIMIT 1
            '''
            result = pd.read_sql_query(query, conn, params=(symbol,))
            conn.close()
            
            if not result.empty:
                current_price = result['close_price'].iloc[0]
                best_model_name = best_model['model']
                best_pred = results[best_model_name]['predictions'][-1]
                
                predicted_change = best_pred - current_price
                change_pct = (predicted_change / current_price) * 100
                
                report += f"ğŸ’° ä¾¡æ ¼äºˆæ¸¬ï¼ˆ{best_model_name}ï¼‰:\n"
                report += f"   ç¾åœ¨ä¾¡æ ¼: {current_price:.2f}\n"
                report += f"   äºˆæ¸¬ä¾¡æ ¼: {best_pred:.2f}\n"
                report += f"   äºˆæ¸¬å¤‰å‹•: {predicted_change:.2f} ({change_pct:.2f}%)\n\n"
        except Exception as e:
            self.logger.error(f"ä¾¡æ ¼äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
        
        return report
    
    def save_models(self, symbol: str, results: dict):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        try:
            for model_name, metrics in results.items():
                if metrics['model'] is not None:
                    model_path = self.model_dir / f"{symbol}_{model_name}_model.pkl"
                    joblib.dump(metrics['model'], model_path)
                    self.logger.info(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_path}")
            
            # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜
            if 'scaler' in self.scalers:
                scaler_path = self.model_dir / f"{symbol}_scaler.pkl"
                joblib.dump(self.scalers['scaler'], scaler_path)
                self.logger.info(f"ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä¿å­˜: {scaler_path}")
                
        except Exception as e:
            self.logger.error(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_previous_trading_day(self) -> str:
        """å‰ã®å–¶æ¥­æ—¥ã‚’å–å¾—ï¼ˆæœˆæ›œã®å ´åˆã¯é‡‘æ›œæ—¥ï¼‰"""
        from datetime import datetime, timedelta
        
        today = datetime.now()
        
        # ä»Šæ—¥ãŒæœˆæ›œæ—¥ï¼ˆ0ï¼‰ã®å ´åˆã¯3æ—¥å‰ï¼ˆé‡‘æ›œæ—¥ï¼‰
        if today.weekday() == 0:  # Monday
            previous_day = today - timedelta(days=3)
        # ä»Šæ—¥ãŒæ—¥æ›œæ—¥ï¼ˆ6ï¼‰ã®å ´åˆã¯2æ—¥å‰ï¼ˆé‡‘æ›œæ—¥ï¼‰  
        elif today.weekday() == 6:  # Sunday
            previous_day = today - timedelta(days=2)
        # ãã®ä»–ã®å ´åˆã¯1æ—¥å‰
        else:
            previous_day = today - timedelta(days=1)
        
        return previous_day.strftime('%Y-%m-%d')
    
    def filter_high_volume_symbols(self, symbols: List[str], min_volume: int = 300000) -> List[str]:
        """å‰ã®å–¶æ¥­æ—¥ã®å–å¼•æ•°é‡ãŒ30ä¸‡æ ªä»¥ä¸Šã®éŠ˜æŸ„ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # å‰ã®å–¶æ¥­æ—¥ã‚’å–å¾—
            previous_trading_day = self.get_previous_trading_day()
            
            self.logger.info(f"å‰ã®å–¶æ¥­æ—¥: {previous_trading_day}")
            
            filtered_symbols = []
            
            for symbol in symbols:
                query = '''
                    SELECT AVG(volume) as avg_volume, COUNT(*) as data_count
                    FROM chart_data 
                    WHERE symbol = ? AND datetime LIKE ? AND timeframe = '5M'
                '''
                
                result = pd.read_sql_query(query, conn, params=(symbol, f'{previous_trading_day}%'))
                
                if not result.empty and result['avg_volume'].iloc[0] is not None:
                    avg_volume = result['avg_volume'].iloc[0]
                    data_count = result['data_count'].iloc[0]
                    
                    if avg_volume >= min_volume:
                        filtered_symbols.append(symbol)
                        self.logger.info(f"âœ… {symbol}: å¹³å‡å‡ºæ¥é«˜ {avg_volume:.0f}æ ª (â‰¥{min_volume}) ãƒ‡ãƒ¼ã‚¿æ•°:{data_count}")
                    else:
                        self.logger.info(f"âŒ {symbol}: å¹³å‡å‡ºæ¥é«˜ {avg_volume:.0f}æ ª (<{min_volume}) ãƒ‡ãƒ¼ã‚¿æ•°:{data_count}")
                else:
                    self.logger.warning(f"âš ï¸ {symbol}: {previous_trading_day}ã®ãƒ‡ãƒ¼ã‚¿ãªã—")
            
            conn.close()
            
            self.logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ: {len(filtered_symbols)}/{len(symbols)}éŠ˜æŸ„ãŒ30ä¸‡æ ªä»¥ä¸Š")
            return filtered_symbols
            
        except Exception as e:
            self.logger.error(f"å‡ºæ¥é«˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            return symbols  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’è¿”ã™

    def run_full_analysis(self, symbols: List[str]) -> Dict:
        """å®Œå…¨ãªåˆ†æã‚’å®Ÿè¡Œï¼ˆãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰è©•ä¾¡ã¾ã§ï¼‰"""
        all_results = {}
        
        # 0. å‡ºæ¥é«˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆ30ä¸‡æ ªä»¥ä¸Šã€å–¶æ¥­æ—¥è€ƒæ…®ï¼‰
        self.logger.info("=== å‡ºæ¥é«˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆ30ä¸‡æ ªä»¥ä¸Šã€å–¶æ¥­æ—¥è€ƒæ…®ï¼‰ ===")
        current_day = datetime.now().strftime('%A')  # æ›œæ—¥åã‚’å–å¾—
        self.logger.info(f"ä»Šæ—¥ã¯{current_day}ã§ã™")
        
        filtered_symbols = self.filter_high_volume_symbols(symbols)
        
        if not filtered_symbols:
            self.logger.warning("âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œã®éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ƒã®éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            filtered_symbols = symbols
        
        # 1. ãƒ‡ãƒ¼ã‚¿åé›†
        self.logger.info("=== yfinanceãƒ‡ãƒ¼ã‚¿åé›† ===")
        if self.collect_yfinance_data(filtered_symbols, days=5):
            self.logger.info("âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
        else:
            self.logger.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿åé›†ã§å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸã€‚æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ...")
        
        # 2. å„éŠ˜æŸ„ã§ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
        for symbol in filtered_symbols:
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ” éŠ˜æŸ„åˆ†æ: {symbol}")
            self.logger.info('='*60)
            
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            X, y, df, feature_cols = self.prepare_data(symbol)
            
            if X is None:
                self.logger.warning(f"âš ï¸ {symbol} ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue
            
            # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
            comparison_results, y_test = self.compare_models(X, y)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_comparison_report(symbol, comparison_results, y_test)
            self.logger.info(f"\n{report}")
            
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            try:
                report_path = self.reports_dir / f'{symbol}_comparison_report.txt'
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(report)
                self.logger.info(f"ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
            except Exception as e:
                self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            self.save_models(symbol, comparison_results)
            
            all_results[symbol] = {
                'comparison_results': comparison_results,
                'y_test': y_test,
                'report': report
            }
        
        # 3. ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœã®ã‚µãƒãƒªãƒ¼
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœã‚µãƒãƒªãƒ¼")
        self.logger.info(f"{'='*60}")
        self.logger.info(f"å…ƒã®éŠ˜æŸ„æ•°: {len(symbols)}")
        self.logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ: {len(filtered_symbols)}")
        self.logger.info(f"åˆ†æå®Œäº†: {len(all_results)}")
        
        return all_results
    
    def print_summary(self, all_results: Dict):
        """å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        self.logger.info(f"\n{'='*60}")
        self.logger.info("ğŸ“ˆ å…¨ä½“ã‚µãƒãƒªãƒ¼")
        self.logger.info('='*60)
        
        for symbol, results in all_results.items():
            comparison_results = results['comparison_results']
            
            # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
            best_model_name = min(comparison_results.keys(), 
                                key=lambda x: comparison_results[x]['mae'])
            best_mae = comparison_results[best_model_name]['mae']
            
            self.logger.info(f"{symbol}: æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ« = {best_model_name} (MAE: {best_mae:.4f})")
        
        # LightGBMã®åˆ©ç”¨çŠ¶æ³
        if lightgbm_available:
            self.logger.info("\nğŸš€ LightGBMãŒåˆ©ç”¨ã•ã‚Œã¾ã—ãŸ")
        else:
            self.logger.info("\nâš ï¸ LightGBMãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ (pip install lightgbm ã§è¿½åŠ å¯èƒ½)")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO, 
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('ml_analysis.log', encoding='utf-8')
        ]
    )
    
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸš€ æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«çµ±åˆåˆ†æã‚·ã‚¹ãƒ†ãƒ  é–‹å§‹")
    logger.info("="*60)
    
    # MLãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
    ml_models = MLTradingModels()
    
    # åˆ†æå¯¾è±¡éŠ˜æŸ„
    symbols = ['7203', '6758', '8306', '9984', '6861']
    logger.info(f"åˆ†æå¯¾è±¡éŠ˜æŸ„: {', '.join(symbols)}")
    
    # å®Œå…¨ãªåˆ†æå®Ÿè¡Œ
    all_results = ml_models.run_full_analysis(symbols)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    ml_models.print_summary(all_results)
    
    logger.info("\nâœ… åˆ†æå®Œäº†!")
    logger.info("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: reports/ãƒ•ã‚©ãƒ«ãƒ€å†…")
    logger.info("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: models/ãƒ•ã‚©ãƒ«ãƒ€å†…")
    logger.info("ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: ml_analysis.log")


if __name__ == "__main__":
    main()
