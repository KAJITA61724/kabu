"""
å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®MLãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºçµ±åˆæ¸ˆã¿MLãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å®Ÿãƒ‡ãƒ¼ã‚¿ã§è©³ç´°æ¤œè¨¼
"""

import sys
sys.path.append('core')

from ml_models import MLTradingModels
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import logging
from datetime import datetime, timedelta
import sqlite3
from pathlib import Path

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']

class MLModelValidator:
    """MLãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.ml_models = MLTradingModels()
        self.logger = logging.getLogger(__name__)
        
        # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.results_dir = Path("validation_results")
        self.results_dir.mkdir(exist_ok=True)
        
        # æ¤œè¨¼å¯¾è±¡éŠ˜æŸ„ï¼ˆç•°ãªã‚‹æ¥­ç¨®ã‚’é¸æŠï¼‰
        self.test_symbols = {
            '7203': 'ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šï¼ˆè‡ªå‹•è»Šï¼‰',
            '6758': 'ã‚½ãƒ‹ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆé›»æ°—æ©Ÿå™¨ï¼‰',
            '8306': 'ä¸‰è±UFJï¼ˆéŠ€è¡Œï¼‰',
            '9984': 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ï¼ˆæƒ…å ±é€šä¿¡ï¼‰',
            '6861': 'ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹ï¼ˆé›»æ°—æ©Ÿå™¨ï¼‰',
            '4503': 'å¤§æ¨¹ç”Ÿå‘½ï¼ˆåŒ–å­¦ï¼‰',
            '7974': 'ä»»å¤©å ‚ï¼ˆãã®ä»–è£½å“ï¼‰'
        }
    
    def collect_validation_data(self, days: int = 10) -> bool:
        """æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®åé›†"""
        print("=== æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿åé›† ===")
        
        symbols = list(self.test_symbols.keys())
        success = self.ml_models.collect_yfinance_data(symbols, days=days)
        
        if success:
            print(f"âœ… {len(symbols)}éŠ˜æŸ„ã®{days}æ—¥é–“ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
            
            # ãƒ‡ãƒ¼ã‚¿é‡ç¢ºèª
            conn = sqlite3.connect(self.ml_models.db_path)
            for symbol in symbols:
                query = "SELECT COUNT(*) FROM chart_data WHERE symbol = ?"
                count = pd.read_sql_query(query, conn, params=(symbol,)).iloc[0, 0]
                print(f"  {symbol} ({self.test_symbols[symbol]}): {count}ä»¶")
            conn.close()
            
        return success
    
    def validate_single_symbol(self, symbol: str) -> dict:
        """å˜ä¸€éŠ˜æŸ„ã®è©³ç´°æ¤œè¨¼"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š {symbol} ({self.test_symbols[symbol]}) ã®è©³ç´°æ¤œè¨¼")
        print('='*60)
        
        results = {}
        
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™ã¨ç‰¹å¾´é‡ä½œæˆ
            X, y, df, feature_cols = self.ml_models.prepare_advanced_data(symbol, period=500)
            
            if X is None:
                print(f"âŒ {symbol}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
                return None
            
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {len(X)}ã‚µãƒ³ãƒ—ãƒ«, {len(feature_cols)}ç‰¹å¾´é‡")
            
            # 2. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨æ¯”è¼ƒ
            model_comparison = self.ml_models.compare_models([symbol])
            
            if symbol not in model_comparison:
                print(f"âŒ {symbol}: ãƒ¢ãƒ‡ãƒ«è¨“ç·´å¤±æ•—")
                return None
            
            model_results = model_comparison[symbol]
            
            # 3. ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
            feature_importance = self._analyze_feature_importance(model_results)
            
            # 4. äºˆæ¸¬ç²¾åº¦ã®æ™‚ç³»åˆ—åˆ†æ
            time_series_analysis = self._time_series_prediction_analysis(X, y, feature_cols, symbol)
            
            # 5. ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåŠ¹æœåˆ†æ
            fundamental_impact = self._analyze_fundamental_impact(df, symbol)
            
            results = {
                'symbol': symbol,
                'company_name': self.test_symbols[symbol],
                'data_size': len(X),
                'feature_count': len(feature_cols),
                'model_results': model_results,
                'feature_importance': feature_importance,
                'time_series_analysis': time_series_analysis,
                'fundamental_impact': fundamental_impact,
                'validation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # 6. çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self._generate_detailed_report(results)
            
            print(f"âœ… {symbol}: æ¤œè¨¼å®Œäº†")
            
        except Exception as e:
            print(f"âŒ {symbol}: æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ - {e}")
            self.logger.error(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ ({symbol}): {e}")
            return None
        
        return results
    
    def _analyze_feature_importance(self, model_results: dict) -> dict:
        """ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ"""
        importance_analysis = {}
        
        for model_name, results in model_results.items():
            if 'feature_importance' in results and results['feature_importance'] is not None:
                feature_imp = results['feature_importance']
                
                # ä¸Šä½10ç‰¹å¾´é‡
                top_features = feature_imp.head(10)
                
                # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ« vs ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æ
                technical_features = []
                fundamental_features = []
                
                for _, row in feature_imp.iterrows():
                    feature_name = row['feature']
                    importance = row['importance']
                    
                    if feature_name in ['per', 'pbr', 'dividend_yield', 'roe', 'roa', 'market_cap',
                                      'eps', 'bps', 'revenue_growth', 'profit_growth', 'debt_ratio',
                                      'sector_avg_per', 'per_vs_sector']:
                        fundamental_features.append((feature_name, importance))
                    else:
                        technical_features.append((feature_name, importance))
                
                technical_importance = sum([imp for _, imp in technical_features])
                fundamental_importance = sum([imp for _, imp in fundamental_features])
                
                importance_analysis[model_name] = {
                    'top_features': top_features.to_dict('records'),
                    'technical_importance': technical_importance,
                    'fundamental_importance': fundamental_importance,
                    'technical_vs_fundamental_ratio': technical_importance / (fundamental_importance + 0.001)
                }
        
        return importance_analysis
    
    def _time_series_prediction_analysis(self, X, y, feature_cols, symbol: str) -> dict:
        """æ™‚ç³»åˆ—äºˆæ¸¬ç²¾åº¦åˆ†æ"""
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.model_selection import TimeSeriesSplit
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
        
        # æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        tscv = TimeSeriesSplit(n_splits=5)
        
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        
        mse_scores = []
        mae_scores = []
        r2_scores = []
        
        for train_index, test_index in tscv.split(X):
            X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]
            y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]
            
            model.fit(X_train_fold, y_train_fold)
            y_pred_fold = model.predict(X_test_fold)
            
            mse_scores.append(mean_squared_error(y_test_fold, y_pred_fold))
            mae_scores.append(mean_absolute_error(y_test_fold, y_pred_fold))
            r2_scores.append(r2_score(y_test_fold, y_pred_fold))
        
        return {
            'cv_mse_mean': np.mean(mse_scores),
            'cv_mse_std': np.std(mse_scores),
            'cv_mae_mean': np.mean(mae_scores),
            'cv_mae_std': np.std(mae_scores),
            'cv_r2_mean': np.mean(r2_scores),
            'cv_r2_std': np.std(r2_scores),
            'stability_score': 1 - (np.std(r2_scores) / (np.mean(r2_scores) + 0.001))
        }
    
    def _analyze_fundamental_impact(self, df: pd.DataFrame, symbol: str) -> dict:
        """ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿ã®ä¾¡æ ¼äºˆæ¸¬ã¸ã®å½±éŸ¿åˆ†æ"""
        fundamental_cols = ['per', 'pbr', 'dividend_yield', 'roe', 'roa']
        
        if not all(col in df.columns for col in fundamental_cols):
            return {'status': 'ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿ãªã—'}
        
        # ä¾¡æ ¼å¤‰å‹•ã¨ã®ç›¸é–¢åˆ†æ
        price_change = df['close_price'].pct_change()
        
        correlations = {}
        for col in fundamental_cols:
            if col in df.columns:
                correlation = df[col].corr(price_change)
                correlations[col] = correlation if not np.isnan(correlation) else 0
        
        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºå€¤ã®è¦ç´„çµ±è¨ˆ
        fundamental_stats = {}
        for col in fundamental_cols:
            if col in df.columns and df[col].notna().any():
                fundamental_stats[col] = {
                    'mean': df[col].mean(),
                    'std': df[col].std(),
                    'current_value': df[col].iloc[-1] if not df[col].empty else 0
                }
        
        return {
            'correlations': correlations,
            'fundamental_stats': fundamental_stats,
            'status': 'ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æå®Œäº†'
        }
    
    def _generate_detailed_report(self, results: dict):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        symbol = results['symbol']
        company_name = results['company_name']
        
        report = f"""
================================================================================
ğŸ¢ {symbol} ({company_name}) è©³ç´°æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ
================================================================================

ğŸ“Š åŸºæœ¬æƒ…å ±:
  â€¢ æ¤œè¨¼æ—¥æ™‚: {results['validation_date']}
  â€¢ ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {results['data_size']:,}ã‚µãƒ³ãƒ—ãƒ«
  â€¢ ç‰¹å¾´é‡æ•°: {results['feature_count']}å€‹
  â€¢ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºçµ±åˆ: âœ… æœ‰åŠ¹

ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ:
"""
        
        # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ
        model_results = results['model_results']
        performance_data = []
        
        for model_name, model_result in model_results.items():
            performance_data.append({
                'model': model_name,
                'mse': model_result['mse'],
                'mae': model_result['mae'],
                'r2': model_result.get('r2', 0)
            })
        
        # æ€§èƒ½é †ã«ã‚½ãƒ¼ãƒˆ
        performance_data.sort(key=lambda x: x['mse'])
        
        for i, perf in enumerate(performance_data, 1):
            report += f"  {i}. {perf['model']}\n"
            report += f"     MSE: {perf['mse']:.4f} | MAE: {perf['mae']:.4f} | RÂ²: {perf['r2']:.4f}\n"
        
        best_model = performance_data[0]
        report += f"\nğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_model['model']}\n"
        
        # ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
        feature_importance = results.get('feature_importance', {})
        if feature_importance:
            report += f"\nğŸ” ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ:\n"
            
            for model_name, importance_data in feature_importance.items():
                if model_name == best_model['model']:
                    tech_imp = importance_data['technical_importance']
                    fund_imp = importance_data['fundamental_importance']
                    ratio = importance_data['technical_vs_fundamental_ratio']
                    
                    report += f"  ğŸ“Š {model_name}:\n"
                    report += f"     ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«é‡è¦åº¦: {tech_imp:.3f} ({tech_imp/(tech_imp+fund_imp)*100:.1f}%)\n"
                    report += f"     ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºé‡è¦åº¦: {fund_imp:.3f} ({fund_imp/(tech_imp+fund_imp)*100:.1f}%)\n"
                    report += f"     ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«/ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºæ¯”: {ratio:.2f}\n"
                    
                    report += f"     ä¸Šä½5ç‰¹å¾´é‡:\n"
                    for feature in importance_data['top_features'][:5]:
                        report += f"       â€¢ {feature['feature']}: {feature['importance']:.4f}\n"
        
        # æ™‚ç³»åˆ—åˆ†æçµæœ
        ts_analysis = results.get('time_series_analysis', {})
        if ts_analysis:
            report += f"\nğŸ“… æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³:\n"
            report += f"  â€¢ å¹³å‡RÂ²: {ts_analysis['cv_r2_mean']:.4f} Â± {ts_analysis['cv_r2_std']:.4f}\n"
            report += f"  â€¢ å¹³å‡MAE: {ts_analysis['cv_mae_mean']:.4f} Â± {ts_analysis['cv_mae_std']:.4f}\n"
            report += f"  â€¢ å®‰å®šæ€§ã‚¹ã‚³ã‚¢: {ts_analysis['stability_score']:.4f}\n"
        
        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºå½±éŸ¿åˆ†æ
        fund_impact = results.get('fundamental_impact', {})
        if fund_impact.get('status') == 'ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æå®Œäº†':
            report += f"\nğŸ’¼ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºå½±éŸ¿åˆ†æ:\n"
            
            correlations = fund_impact.get('correlations', {})
            if correlations:
                report += f"  ä¾¡æ ¼å¤‰å‹•ã¨ã®ç›¸é–¢:\n"
                for metric, corr in correlations.items():
                    if abs(corr) > 0.1:
                        direction = "æ­£ã®ç›¸é–¢" if corr > 0 else "è² ã®ç›¸é–¢"
                        report += f"    â€¢ {metric}: {corr:.3f} ({direction})\n"
            
            fund_stats = fund_impact.get('fundamental_stats', {})
            if fund_stats:
                report += f"  ç¾åœ¨ã®ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºæŒ‡æ¨™:\n"
                for metric, stats in fund_stats.items():
                    current = stats['current_value']
                    if metric == 'per':
                        report += f"    â€¢ PER: {current:.2f}\n"
                    elif metric == 'pbr':
                        report += f"    â€¢ PBR: {current:.2f}\n"
                    elif metric == 'dividend_yield':
                        report += f"    â€¢ é…å½“åˆ©å›ã‚Š: {current:.2f}%\n"
                    elif metric == 'roe':
                        report += f"    â€¢ ROE: {current*100:.2f}%\n"
                    elif metric == 'roa':
                        report += f"    â€¢ ROA: {current*100:.2f}%\n"
        
        # æŠ•è³‡åˆ¤æ–­
        report += f"\nğŸ’¡ AIæŠ•è³‡åˆ¤æ–­:\n"
        
        r2_score = best_model['r2']
        mae_score = best_model['mae']
        stability = ts_analysis.get('stability_score', 0)
        
        if r2_score > 0.7 and stability > 0.7:
            judgment = "ğŸŸ¢ å¼·ã„è²·ã„æ¨å¥¨"
        elif r2_score > 0.5 and stability > 0.5:
            judgment = "ğŸŸ¡ æ¡ä»¶ä»˜ãæ¨å¥¨"
        elif r2_score > 0.3:
            judgment = "ğŸŸ  æ³¨æ„æ·±ãç›£è¦–"
        else:
            judgment = "ğŸ”´ æŠ•è³‡éæ¨å¥¨"
        
        report += f"  {judgment}\n"
        report += f"  â€¢ äºˆæ¸¬ç²¾åº¦: {r2_score:.1%}\n"
        report += f"  â€¢ äºˆæ¸¬å®‰å®šæ€§: {stability:.1%}\n"
        report += f"  â€¢ äºˆæ¸¬èª¤å·®: Â±{mae_score:.2f}å††\n"
        
        report += f"\n" + "="*80 + "\n"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_file = self.results_dir / f"{symbol}_detailed_validation_report.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        print(f"\n{report}")
    
    def run_comprehensive_validation(self):
        """åŒ…æ‹¬çš„æ¤œè¨¼ã®å®Ÿè¡Œ"""
        print("ğŸš€ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºçµ±åˆMLãƒ¢ãƒ‡ãƒ« å®Ÿãƒ‡ãƒ¼ã‚¿æ¤œè¨¼é–‹å§‹")
        print("="*80)
        
        # 1. ãƒ‡ãƒ¼ã‚¿åé›†
        if not self.collect_validation_data(days=15):
            print("âŒ ãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—")
            return False
        
        # 2. å„éŠ˜æŸ„ã®è©³ç´°æ¤œè¨¼
        all_results = {}
        for symbol in self.test_symbols.keys():
            result = self.validate_single_symbol(symbol)
            if result:
                all_results[symbol] = result
        
        # 3. ç·åˆæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ
        self._generate_comprehensive_summary(all_results)
        
        print("\nğŸ‰ åŒ…æ‹¬çš„æ¤œè¨¼å®Œäº†ï¼")
        print(f"ğŸ“ çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.results_dir}")
        
        return True
    
    def _generate_comprehensive_summary(self, all_results: dict):
        """ç·åˆæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        summary = """
================================================================================
ğŸ† ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºçµ±åˆMLãƒ¢ãƒ‡ãƒ« ç·åˆæ¤œè¨¼ã‚µãƒãƒªãƒ¼
================================================================================

"""
        
        # å„éŠ˜æŸ„ã®æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
        summary += "ğŸ“Š éŠ˜æŸ„åˆ¥æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ:\n\n"
        
        for symbol, results in all_results.items():
            company_name = results['company_name']
            model_results = results['model_results']
            
            # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«ç‰¹å®š
            best_model_name = min(model_results.items(), key=lambda x: x[1]['mse'])[0]
            best_model = model_results[best_model_name]
            
            summary += f"ğŸ¢ {symbol} ({company_name}):\n"
            summary += f"  æœ€å„ªç§€: {best_model_name}\n"
            summary += f"  RÂ²: {best_model.get('r2', 0):.3f} | MAE: {best_model['mae']:.2f}\n"
            
            # å®‰å®šæ€§ã‚¹ã‚³ã‚¢
            ts_analysis = results.get('time_series_analysis', {})
            stability = ts_analysis.get('stability_score', 0)
            summary += f"  å®‰å®šæ€§: {stability:.3f}\n\n"
        
        # æ¥­ç¨®åˆ¥åˆ†æ
        summary += "ğŸ­ æ¥­ç¨®åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:\n\n"
        
        sector_performance = {}
        for symbol, results in all_results.items():
            company_name = results['company_name']
            sector = company_name.split('ï¼ˆ')[1].split('ï¼‰')[0] if 'ï¼ˆ' in company_name else 'ãã®ä»–'
            
            best_model = min(results['model_results'].items(), key=lambda x: x[1]['mse'])[1]
            r2_score = best_model.get('r2', 0)
            
            if sector not in sector_performance:
                sector_performance[sector] = []
            sector_performance[sector].append(r2_score)
        
        for sector, scores in sector_performance.items():
            avg_score = np.mean(scores)
            summary += f"  {sector}: å¹³å‡RÂ² {avg_score:.3f}\n"
        
        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåŠ¹æœåˆ†æ
        summary += f"\nğŸ’¼ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºçµ±åˆåŠ¹æœ:\n\n"
        
        tech_vs_fund_ratios = []
        for symbol, results in all_results.items():
            feature_importance = results.get('feature_importance', {})
            for model_name, importance_data in feature_importance.items():
                if 'technical_vs_fundamental_ratio' in importance_data:
                    ratio = importance_data['technical_vs_fundamental_ratio']
                    tech_vs_fund_ratios.append(ratio)
        
        if tech_vs_fund_ratios:
            avg_ratio = np.mean(tech_vs_fund_ratios)
            summary += f"  å¹³å‡ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«/ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºé‡è¦åº¦æ¯”: {avg_ratio:.2f}\n"
            
            if avg_ratio > 2:
                summary += "  â†’ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æãŒæ”¯é…çš„\n"
            elif avg_ratio > 0.5:
                summary += "  â†’ ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸçµ±åˆåˆ†æ\n"
            else:
                summary += "  â†’ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æãŒæ”¯é…çš„\n"
        
        summary += f"\nğŸ¯ ç·åˆè©•ä¾¡:\n"
        
        # å…¨ä½“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        all_r2_scores = []
        for symbol, results in all_results.items():
            best_model = min(results['model_results'].items(), key=lambda x: x[1]['mse'])[1]
            all_r2_scores.append(best_model.get('r2', 0))
        
        avg_r2 = np.mean(all_r2_scores)
        summary += f"  å¹³å‡äºˆæ¸¬ç²¾åº¦: {avg_r2:.1%}\n"
        
        if avg_r2 > 0.6:
            summary += "  âœ… å„ªç§€ãªäºˆæ¸¬æ€§èƒ½\n"
        elif avg_r2 > 0.4:
            summary += "  ğŸŸ¡ è‰¯å¥½ãªäºˆæ¸¬æ€§èƒ½\n"
        else:
            summary += "  ğŸŸ  æ”¹å–„ãŒå¿…è¦\n"
        
        summary += f"\nğŸ“ˆ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºçµ±åˆã®ä¾¡å€¤:\n"
        summary += f"  â€¢ å¤šè§’çš„åˆ†æã«ã‚ˆã‚‹äºˆæ¸¬ç²¾åº¦å‘ä¸Š\n"
        summary += f"  â€¢ æ¥­ç¨®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸéŠ˜æŸ„è©•ä¾¡\n"
        summary += f"  â€¢ é•·æœŸæŠ•è³‡åˆ¤æ–­ã®æ ¹æ‹ æä¾›\n"
        
        summary += "\n" + "="*80 + "\n"
        
        # ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        summary_file = self.results_dir / "comprehensive_validation_summary.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        print(f"ğŸ“„ ç·åˆã‚µãƒãƒªãƒ¼ä¿å­˜: {summary_file}")
        print(summary)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # æ¤œè¨¼å®Ÿè¡Œ
    validator = MLModelValidator()
    validator.run_comprehensive_validation()

if __name__ == "__main__":
    main()
