"""
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ« - æ–¹æ³•1ã®å®Ÿè£…
- 1æ™‚é–“ç·šå½¢äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
- 5åˆ†è¶³ä¸Šä¸‹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
- ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
- ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æçµ±åˆ
"""

import pandas as pd
import numpy as np
import sqlite3
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
import joblib
from pathlib import Path
import sys
import os

# yfinanceãƒ‡ãƒ¼ã‚¿åé›†ã¨ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿åé›†å™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from fundamental_data_collector import FundamentalDataCollector
except ImportError:
    FundamentalDataCollector = None

# yfinanceã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import yfinance as yf
    yfinance_available = True
except ImportError:
    yfinance_available = False

# scikit-learnã®è¿½åŠ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from sklearn.metrics import mean_absolute_error, r2_score
    sklearn_available = True
except ImportError:
    sklearn_available = False

# LightGBMã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import lightgbm as lgb
    lightgbm_available = True
except ImportError:
    lightgbm_available = False

class MLTradingModels:
    """æ©Ÿæ¢°å­¦ç¿’å–å¼•ãƒ¢ãƒ‡ãƒ« - yfinanceãƒ‡ãƒ¼ã‚¿å¯¾å¿œ"""
    
    def __init__(self, db_path: str = "trading_data.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.hourly_model = LinearRegression()
        self.minute_model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.scaler = StandardScaler()
        
        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿åé›†å™¨
        if FundamentalDataCollector:
            self.fundamental_collector = FundamentalDataCollector()
        else:
            self.fundamental_collector = None
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‘ã‚¹
        self.model_dir = Path("models")
        self.model_dir.mkdir(exist_ok=True)
        
        # äºˆæ¸¬ç²¾åº¦è¿½è·¡
        self.prediction_history = []
        
        # çµ±åˆæ©Ÿèƒ½ç”¨ã®è¿½åŠ ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
        self.feature_columns = None
        self.advanced_model = None  # é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ç”¨
        
    def collect_yfinance_data(self, symbols: List[str], days: int = 5) -> bool:
        """yfinanceã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        if not yfinance_available:
            self.logger.error("yfinanceãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS chart_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    datetime TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    open_price REAL NOT NULL,
                    high_price REAL NOT NULL,
                    low_price REAL NOT NULL,
                    close_price REAL NOT NULL,
                    volume INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(symbol, datetime, timeframe)
                )
            ''')
            
            success_count = 0
            total_data = 0
            
            for symbol in symbols:
                try:
                    # yfinanceã§ãƒ‡ãƒ¼ã‚¿å–å¾—
                    yahoo_symbol = f"{symbol}.T"
                    end_date = datetime.now()
                    start_date = end_date - timedelta(days=days)
                    
                    ticker = yf.Ticker(yahoo_symbol)
                    data = ticker.history(start=start_date, end=end_date, interval="5m")
                    
                    if data.empty:
                        self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yahoo_symbol}")
                        continue
                    
                    # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
                    df = data.reset_index()
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    for _, row in df.iterrows():
                        cursor.execute('''
                            INSERT OR REPLACE INTO chart_data 
                            (symbol, datetime, timeframe, open_price, high_price, low_price, close_price, volume)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            symbol,
                            row['Datetime'].strftime('%Y-%m-%d %H:%M:%S'),
                            '5M',
                            row['Open'],
                            row['High'],
                            row['Low'],
                            row['Close'],
                            int(row['Volume'])
                        ))
                    
                    success_count += 1
                    total_data += len(df)
                    self.logger.info(f"âœ… {symbol}: {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜")
                    
                except Exception as e:
                    self.logger.error(f"âŒ {symbol}ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {success_count}/{len(symbols)}éŠ˜æŸ„, {total_data}ä»¶")
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def prepare_features(self, symbol: str, target_time: datetime, lookback_hours: int = 72, use_fundamental: bool = True) -> Optional[np.ndarray]:
        """ç‰¹å¾´é‡æº–å‚™ - yfinanceãƒ‡ãƒ¼ã‚¿å¯¾å¿œ"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # éå»72æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾— (chart_dataãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰)
            start_time = target_time - timedelta(hours=lookback_hours)
            
            query = '''
                SELECT 
                    datetime,
                    close_price,
                    volume,
                    open_price,
                    high_price,
                    low_price
                FROM chart_data 
                WHERE symbol = ? AND datetime >= ? AND datetime <= ?
                ORDER BY datetime
            '''
            
            df = pd.read_sql_query(query, conn, params=(symbol, start_time.strftime('%Y-%m-%d %H:%M:%S'), target_time.strftime('%Y-%m-%d %H:%M:%S')))
            conn.close()
            
            if len(df) < 24:  # æœ€ä½2æ™‚é–“åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
                return None
            
            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ç‰¹å¾´é‡è¨ˆç®—
            features = []
            
            # ç§»å‹•å¹³å‡
            df['ma_5'] = df['close_price'].rolling(window=5).mean()
            df['ma_20'] = df['close_price'].rolling(window=20).mean()
            df['ma_60'] = df['close_price'].rolling(window=60).mean()
            
            features.extend([
                df['ma_5'].iloc[-1] if not pd.isna(df['ma_5'].iloc[-1]) else df['close_price'].iloc[-1],
                df['ma_20'].iloc[-1] if not pd.isna(df['ma_20'].iloc[-1]) else df['close_price'].iloc[-1],
                df['ma_60'].iloc[-1] if not pd.isna(df['ma_60'].iloc[-1]) else df['close_price'].iloc[-1]
            ])
            
            # ä¾¡æ ¼é–¢é€£
            current_price = df['close_price'].iloc[-1]
            features.extend([
                current_price,
                df['close_price'].pct_change().iloc[-5:].mean(),  # ç›´è¿‘5åˆ†é–“ã®å¹³å‡å¤‰åŒ–ç‡
                df['volume'].iloc[-12:].mean(),  # ç›´è¿‘1æ™‚é–“ã®å¹³å‡å‡ºæ¥é«˜
            ])
            
            # ä¾¡æ ¼æ¯”ç‡ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚’é˜²ãï¼‰
            features.extend([
                df['high_price'].iloc[-1] / df['low_price'].iloc[-1] if df['low_price'].iloc[-1] != 0 else 1.0,  # é«˜å€¤/å®‰å€¤æ¯”
                df['open_price'].iloc[-1] / df['close_price'].iloc[-1] if df['close_price'].iloc[-1] != 0 else 1.0,  # å§‹å€¤/çµ‚å€¤æ¯”
                (df['close_price'].iloc[-1] / df['volume'].iloc[-1] * 1000000) if df['volume'].iloc[-1] != 0 else 0.0  # ä¾¡æ ¼/å‡ºæ¥é«˜æ¯”
            ])
            
            # æ¥­ç•Œãƒ•ãƒ©ã‚°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            sector_flag = self.get_sector_flag(symbol)
            features.append(sector_flag)
            
            # å‰3æ—¥é–“ã®æ—¥è¶³ãƒ‡ãƒ¼ã‚¿
            daily_features = self.get_daily_features(symbol, target_time)
            features.extend(daily_features)
            
            # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡è¿½åŠ 
            if use_fundamental and self.fundamental_collector:
                fundamental_features = self.get_fundamental_features(symbol, target_time)
                features.extend(fundamental_features)
            else:
                # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                features.extend([0.0] * 12)
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            self.logger.error(f"ç‰¹å¾´é‡æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_fundamental_features(self, symbol: str, target_time: datetime) -> List[float]:
        """ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡å–å¾—"""
        try:
            if not self.fundamental_collector:
                return [0.0] * 12
            
            # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿å–å¾—
            fundamental_data = self.fundamental_collector.get_fundamental_data_from_db(
                symbol, target_time.date()
            )
            
            if not fundamental_data:
                # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                return [0.0] * 12
            
            # ç›¸å¯¾è©•ä¾¡æŒ‡æ¨™å–å¾—
            relative_metrics = self.fundamental_collector.get_relative_valuation(symbol)
            
            # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡
            fund_features = [
                fundamental_data.per,
                fundamental_data.pbr,
                fundamental_data.psr,
                fundamental_data.dividend_yield,
                fundamental_data.roe,
                fundamental_data.roa,
                fundamental_data.debt_ratio,
                fundamental_data.revenue_growth,
                fundamental_data.profit_growth,
                fundamental_data.operating_margin,
                relative_metrics.get('per_ratio', 1.0),
                relative_metrics.get('pbr_ratio', 1.0)
            ]
            
            return fund_features
            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡å–å¾—ã‚¨ãƒ©ãƒ¼ {symbol}: {e}")
            return [0.0] * 12
    
    def get_sector_flag(self, symbol: str) -> float:
        """æ¥­ç•Œãƒ•ãƒ©ã‚°å–å¾—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # prime_symbols.csvã‹ã‚‰æ¥­ç•Œæƒ…å ±å–å¾—
        try:
            df = pd.read_csv("prime_symbols.csv")
            sector_row = df[df['symbol'] == int(symbol)]
            if not sector_row.empty:
                sector = sector_row['sector'].iloc[0]
                # æ¥­ç•Œã‚’æ•°å€¤ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                sector_mapping = {
                    'é›»æ©Ÿ': 1, 'è‡ªå‹•è»Š': 2, 'éŠ€è¡Œ': 3, 'åŒ–å­¦': 4, 'æ©Ÿæ¢°': 5,
                    'æƒ…å ±é€šä¿¡': 6, 'å»ºè¨­': 7, 'é£Ÿå“': 8, 'åŒ»è–¬å“': 9, 'ä¸å‹•ç”£': 10
                }
                return sector_mapping.get(sector, 0)
        except:
            pass
        return 0
    
    def get_daily_features(self, symbol: str, target_time: datetime) -> List[float]:
        """å‰3æ—¥é–“ã®æ—¥è¶³ãƒ‡ãƒ¼ã‚¿ç‰¹å¾´é‡"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # å‰3æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ (chart_dataãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰)
            start_date = (target_time - timedelta(days=3)).date()
            
            query = '''
                SELECT 
                    DATE(datetime) as date,
                    MIN(close_price) as low,
                    MAX(close_price) as high,
                    SUM(volume) as daily_volume,
                    AVG(close_price) as avg_price
                FROM chart_data
                WHERE symbol = ? AND DATE(datetime) >= ? AND timeframe = '5M'
                GROUP BY DATE(datetime)
                ORDER BY date DESC
                LIMIT 3
            '''
            
            df = pd.read_sql_query(query, conn, params=(symbol, start_date.strftime('%Y-%m-%d')))
            conn.close()
            
            if len(df) < 3:
                return [0, 0, 0, 0, 0, 0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            
            # 3æ—¥é–“ã®å¤‰åŒ–ç‡
            price_changes = df['avg_price'].pct_change().fillna(0).tolist()[-2:]
            volume_avg = df['daily_volume'].mean()
            volatility = (df['high'] - df['low']).mean() / df['avg_price'].mean()
            
            return price_changes + [volume_avg, volatility, df['avg_price'].iloc[0], df['daily_volume'].iloc[0]]
            
        except Exception as e:
            self.logger.error(f"æ—¥è¶³ç‰¹å¾´é‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return [0, 0, 0, 0, 0, 0]
    
    def train_hourly_model(self, symbols: List[str], lookback_days: int = 30):
        """1æ™‚é–“ç·šå½¢äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        self.logger.info("1æ™‚é–“äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        
        X_data = []
        y_data = []
        
        conn = sqlite3.connect(self.db_path)
        
        for symbol in symbols:
            try:
                # éå»30æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ (chart_dataãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰)
                end_date = datetime.now()
                start_date = end_date - timedelta(days=lookback_days)
                
                query = '''
                    SELECT datetime, close_price
                    FROM chart_data
                    WHERE symbol = ? AND datetime >= ? AND datetime <= ? 
                    AND timeframe = '5M'
                    ORDER BY datetime
                '''
                
                df = pd.read_sql_query(query, conn, params=(symbol, start_date.strftime('%Y-%m-%d %H:%M:%S'), end_date.strftime('%Y-%m-%d %H:%M:%S')))
                
                if len(df) < 100:  # æœ€ä½ãƒ‡ãƒ¼ã‚¿é‡ãƒã‚§ãƒƒã‚¯
                    continue
                
                # 1æ™‚é–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆä½œæˆ
                for i in range(0, len(df) - 12, 12):  # 1æ™‚é–“ = 12 * 5åˆ†
                    current_time = pd.to_datetime(df.iloc[i]['datetime'])
                    
                    # ç‰¹å¾´é‡æº–å‚™
                    features = self.prepare_features(symbol, current_time)
                    if features is None:
                        continue
                    
                    # 1æ™‚é–“å¾Œã®ä¾¡æ ¼ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰
                    if i + 12 < len(df):
                        future_price = df.iloc[i + 12]['close_price']
                        current_price = df.iloc[i]['close_price']
                        price_change_rate = (future_price - current_price) / current_price
                        
                        X_data.append(features.flatten())
                        y_data.append(price_change_rate)
                
            except Exception as e:
                self.logger.error(f"ã‚·ãƒ³ãƒœãƒ« {symbol} ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        conn.close()
        
        if len(X_data) < 50:
            self.logger.error("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return False
        
        X_data = np.array(X_data)
        y_data = np.array(y_data)
        
        # ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–
        X_scaled = self.scaler.fit_transform(X_data)
        
        # è¨“ç·´
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_data, test_size=0.2, random_state=42)
        
        self.hourly_model.fit(X_train, y_train)
        
        # ç²¾åº¦è©•ä¾¡
        y_pred = self.hourly_model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        
        self.logger.info(f"1æ™‚é–“äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† - MSE: {mse:.6f}")
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        joblib.dump(self.hourly_model, self.model_dir / "hourly_model.pkl")
        joblib.dump(self.scaler, self.model_dir / "scaler.pkl")
        
        return True
    
    def train_minute_model(self, symbols: List[str], lookback_days: int = 30):
        """5åˆ†è¶³ä¸Šä¸‹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        self.logger.info("5åˆ†è¶³äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        
        X_data = []
        y_data = []
        
        conn = sqlite3.connect(self.db_path)
        
        for symbol in symbols:
            try:
                end_date = datetime.now()
                start_date = end_date - timedelta(days=lookback_days)
                
                query = '''
                    SELECT datetime, close_price
                    FROM chart_data
                    WHERE symbol = ? AND datetime >= ? AND datetime <= ?
                    AND timeframe = '5M'
                    ORDER BY datetime
                '''
                
                df = pd.read_sql_query(query, conn, params=(symbol, start_date.strftime('%Y-%m-%d %H:%M:%S'), end_date.strftime('%Y-%m-%d %H:%M:%S')))
                
                if len(df) < 50:
                    continue
                
                # 5åˆ†ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆä½œæˆ
                for i in range(len(df) - 1):
                    current_time = pd.to_datetime(df.iloc[i]['datetime'])
                    
                    features = self.prepare_features(symbol, current_time)
                    if features is None:
                        continue
                    
                    # æ¬¡ã®5åˆ†å¾Œã®ä¾¡æ ¼å¤‰å‹•ï¼ˆä¸ŠãŒã‚‹=1, ä¸‹ãŒã‚‹=0ï¼‰
                    current_price = df.iloc[i]['close_price']
                    next_price = df.iloc[i + 1]['close_price']
                    direction = 1 if next_price > current_price else 0
                    
                    X_data.append(features.flatten())
                    y_data.append(direction)
                
            except Exception as e:
                self.logger.error(f"ã‚·ãƒ³ãƒœãƒ« {symbol} ã®5åˆ†è¶³è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        conn.close()
        
        if len(X_data) < 50:
            self.logger.error("5åˆ†è¶³è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return False
        
        X_data = np.array(X_data)
        y_data = np.array(y_data)
        
        # è¨“ç·´
        X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)
        
        self.minute_model.fit(X_train, y_train)
        
        # ç²¾åº¦è©•ä¾¡
        y_pred = self.minute_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        self.logger.info(f"5åˆ†è¶³äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† - ç²¾åº¦: {accuracy:.3f}")
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        joblib.dump(self.minute_model, self.model_dir / "minute_model.pkl")
        
        return True
    
    def predict_hourly_trend(self, symbol: str, current_time: datetime) -> Optional[float]:
        """1æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬"""
        try:
            features = self.prepare_features(symbol, current_time)
            if features is None:
                return None
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            if not hasattr(self, 'hourly_model') or self.hourly_model is None:
                self.load_models()
            
            features_scaled = self.scaler.transform(features)
            prediction = self.hourly_model.predict(features_scaled)[0]
            
            return prediction
            
        except Exception as e:
            self.logger.error(f"1æ™‚é–“äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict_minute_direction(self, symbol: str, current_time: datetime) -> Optional[Tuple[int, float]]:
        """5åˆ†è¶³æ–¹å‘äºˆæ¸¬ï¼ˆæ–¹å‘, ç¢ºç‡ï¼‰"""
        try:
            features = self.prepare_features(symbol, current_time)
            if features is None:
                return None
            
            if not hasattr(self, 'minute_model') or self.minute_model is None:
                self.load_models()
            
            # äºˆæ¸¬ã¨ç¢ºç‡
            prediction = self.minute_model.predict(features)[0]
            probabilities = self.minute_model.predict_proba(features)[0]
            confidence = max(probabilities)
            
            return prediction, confidence
            
        except Exception as e:
            self.logger.error(f"5åˆ†è¶³äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def fact_check_predictions(self, symbol: str, current_time: datetime) -> Dict:
        """ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        result = {
            'should_trade': False,
            'direction': None,
            'confidence': 0.0,
            'hourly_prediction': None,
            'minute_prediction': None,
            'minute_confidence': 0.0
        }
        
        try:
            # 1æ™‚é–“äºˆæ¸¬
            hourly_pred = self.predict_hourly_trend(symbol, current_time)
            if hourly_pred is None:
                return result
            
            # 5åˆ†è¶³äºˆæ¸¬
            minute_result = self.predict_minute_direction(symbol, current_time)
            if minute_result is None:
                return result
            
            minute_pred, minute_conf = minute_result
            
            # æ–¹å‘ã®ä¸€è‡´ãƒã‚§ãƒƒã‚¯
            hourly_direction = 1 if hourly_pred > 0 else 0
            directions_match = hourly_direction == minute_pred
            
            # 5åˆ†è¶³ã®ä¿¡é ¼åº¦ãŒ80%ä»¥ä¸Šã‹ãƒã‚§ãƒƒã‚¯
            high_confidence = minute_conf >= 0.8
            
            result.update({
                'hourly_prediction': hourly_pred,
                'minute_prediction': minute_pred,
                'minute_confidence': minute_conf,
                'should_trade': directions_match and high_confidence,
                'direction': minute_pred if directions_match and high_confidence else None,
                'confidence': minute_conf
            })
            
            self.logger.info(f"ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ - å–å¼•å®Ÿè¡Œ: {result['should_trade']}, æ–¹å‘: {result['direction']}, ä¿¡é ¼åº¦: {result['confidence']:.3f}")
            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def load_models(self):
        """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            if (self.model_dir / "hourly_model.pkl").exists():
                self.hourly_model = joblib.load(self.model_dir / "hourly_model.pkl")
                self.scaler = joblib.load(self.model_dir / "scaler.pkl")
                
            if (self.model_dir / "minute_model.pkl").exists():
                self.minute_model = joblib.load(self.model_dir / "minute_model.pkl")
                
            self.logger.info("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            
        except Exception as e:
            self.logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def validate_prediction(self, symbol: str, prediction_time: datetime, actual_time: datetime):
        """äºˆæ¸¬ç²¾åº¦æ¤œè¨¼"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # å®Ÿéš›ã®ä¾¡æ ¼å–å¾—
            query = '''
                SELECT close_price 
                FROM chart_data 
                WHERE symbol = ? AND datetime = ? AND timeframe = '5M'
            '''
            
            pred_result = pd.read_sql_query(query, conn, params=(symbol, prediction_time.strftime('%Y-%m-%d %H:%M:%S')))
            actual_result = pd.read_sql_query(query, conn, params=(symbol, actual_time.strftime('%Y-%m-%d %H:%M:%S')))
            
            if len(pred_result) > 0 and len(actual_result) > 0:
                pred_price = pred_result.iloc[0]['close_price']
                actual_price = actual_result.iloc[0]['close_price']
                
                # æ–¹å‘ã®æ­£ç¢ºæ€§
                predicted_direction = 1 if actual_price > pred_price else 0
                
                # äºˆæ¸¬å±¥æ­´ã«è¿½åŠ 
                self.prediction_history.append({
                    'symbol': symbol,
                    'prediction_time': prediction_time,
                    'actual_time': actual_time,
                    'predicted_direction': predicted_direction,
                    'actual_direction': predicted_direction,
                    'accuracy': 1 if predicted_direction == predicted_direction else 0
                })
            
            conn.close()
            
        except Exception as e:
            self.logger.error(f"äºˆæ¸¬æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")

    def create_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """é«˜åº¦ãªç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆml_prediction_model.pyã‹ã‚‰çµ±åˆï¼‰"""
        if df.empty or len(df) < 10:
            return pd.DataFrame()
        
        df = df.copy()
        
        # åŸºæœ¬çš„ãªç‰¹å¾´é‡ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚’é˜²ãï¼‰
        df['price_change'] = df['close_price'].pct_change()
        df['high_low_ratio'] = df['high_price'] / df['low_price'].replace(0, np.nan)
        df['open_close_ratio'] = df['open_price'] / df['close_price'].replace(0, np.nan)
        df['volume_price_ratio'] = df['volume'] / df['close_price'].replace(0, np.nan)
        
        # ç§»å‹•å¹³å‡
        df['sma_5'] = df['close_price'].rolling(window=5).mean()
        df['sma_10'] = df['close_price'].rolling(window=10).mean()
        df['sma_ratio'] = df['close_price'] / df['sma_5'].replace(0, np.nan)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        df['volatility_5'] = df['close_price'].rolling(window=5).std()
        df['volatility_10'] = df['close_price'].rolling(window=10).std()
        
        # å‡ºæ¥é«˜ç³»
        df['volume_sma_5'] = df['volume'].rolling(window=5).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma_5'].replace(0, np.nan)
        
        # RSIï¼ˆç°¡æ˜“ç‰ˆï¼‰
        delta = df['close_price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆéå»ã®å€¤ï¼‰
        for lag in [1, 2, 3, 5]:
            df[f'close_lag_{lag}'] = df['close_price'].shift(lag)
            df[f'volume_lag_{lag}'] = df['volume'].shift(lag)
            df[f'change_lag_{lag}'] = df['price_change'].shift(lag)
        
        # æ™‚é–“ç³»ç‰¹å¾´é‡
        df['hour'] = pd.to_datetime(df['datetime']).dt.hour
        df['minute'] = pd.to_datetime(df['datetime']).dt.minute
        df['time_of_day'] = df['hour'] * 60 + df['minute']
        
        # ç›®æ¨™å¤‰æ•°ï¼ˆæ¬¡ã®æœŸé–“ã®ä¾¡æ ¼ï¼‰
        df['target'] = df['close_price'].shift(-1)
        
        return df

    def prepare_advanced_data(self, symbol: str, period: int = 1000) -> tuple:
        """é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆml_prediction_model.pyã‹ã‚‰çµ±åˆï¼‰"""
        self.logger.info(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­: {symbol}")
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            # yfinanceãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            query = '''
                SELECT datetime, open_price, high_price, low_price, close_price, volume
                FROM chart_data
                WHERE symbol = ? AND timeframe = '5M'
                ORDER BY datetime DESC
                LIMIT ?
            '''
            
            df = pd.read_sql_query(query, conn, params=(symbol, period))
            conn.close()
            
            if df.empty:
                self.logger.error(f"âŒ {symbol} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None, None, None, None
            
            self.logger.info(f"å–å¾—ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã³æ›¿ãˆ
            df = df.sort_values('datetime').reset_index(drop=True)
            
            # ç‰¹å¾´é‡ã‚’ä½œæˆ
            df = self.create_advanced_features(df)
            
            # ç‰¹å¾´é‡ã®åˆ—ã‚’å®šç¾©
            feature_cols = [
                'price_change', 'high_low_ratio', 'open_close_ratio', 'volume_price_ratio',
                'sma_ratio', 'volatility_5', 'volatility_10', 'volume_ratio', 'rsi',
                'close_lag_1', 'close_lag_2', 'close_lag_3', 'close_lag_5',
                'volume_lag_1', 'volume_lag_2', 'volume_lag_3', 'volume_lag_5',
                'change_lag_1', 'change_lag_2', 'change_lag_3', 'change_lag_5',
                'hour', 'minute', 'time_of_day'
            ]
            
            # æ¬ æå€¤ã‚’å‰Šé™¤
            df = df.dropna()
            
            if len(df) < 50:
                self.logger.error(f"âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({len(df)}ä»¶)")
                return None, None, None, None
            
            # ç‰¹å¾´é‡ã¨ç›®æ¨™å¤‰æ•°ã‚’åˆ†é›¢
            X = df[feature_cols].copy()
            y = df['target'].copy()
            
            # NaNã‚„ç„¡é™å¤§ã®å€¤ã‚’å‡¦ç†
            X = X.replace([np.inf, -np.inf], np.nan)
            X = X.fillna(X.median())
            
            # ã•ã‚‰ã«ç„¡é™å¤§ã‚„ç•°å¸¸å€¤ã‚’ã‚¯ãƒªãƒƒãƒ—
            X = X.clip(-1e6, 1e6)
            
            self.logger.info(f"ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
            self.logger.info(f"æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
            
            self.feature_columns = feature_cols
            
            return X, y, df, feature_cols
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, None, None

    def train_advanced_model(self, X, y, model_type='comparison'):
        """é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ï¼ˆæ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰è¿½åŠ ï¼‰"""
        if model_type == 'comparison':
            return self.compare_models(X, y)
        elif sklearn_available and model_type == 'advanced':
            return self._train_sklearn_model(X, y)
        else:
            return self._train_simple_model(X, y)
    
    def _train_sklearn_model(self, X, y):
        """scikit-learnã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        self.logger.info("é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ï¼ˆRandom Forestï¼‰ã‚’è¨“ç·´ä¸­...")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=False
        )
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.advanced_model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.advanced_model.fit(X_train_scaled, y_train)
        
        # äºˆæ¸¬
        y_pred = self.advanced_model.predict(X_test_scaled)
        
        # è©•ä¾¡æŒ‡æ¨™
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        self.logger.info(f"MSE: {mse:.4f}")
        self.logger.info(f"RÂ²: {r2:.4f}")
        self.logger.info(f"MAE: {mae:.4f}")
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        if self.feature_columns:
            feature_importance = pd.DataFrame({
                'feature': self.feature_columns,
                'importance': self.advanced_model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            self.logger.info("\nä¸Šä½10ã®é‡è¦ãªç‰¹å¾´é‡:")
            for _, row in feature_importance.head(10).iterrows():
                self.logger.info(f"  {row['feature']}: {row['importance']:.4f}")
        
        return {
            'model_type': 'RandomForest',
            'mse': mse,
            'r2': r2,
            'mae': mae,
            'feature_importance': feature_importance if self.feature_columns else None,
            'test_predictions': y_pred,
            'test_actual': y_test.values,
            'scaler': scaler
        }
    
    def _train_simple_model(self, X, y):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        self.logger.info("ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ï¼ˆç§»å‹•å¹³å‡ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’è¨“ç·´ä¸­...")
        
        # å˜ç´”ãªç§»å‹•å¹³å‡ãƒ¢ãƒ‡ãƒ«
        window = 5
        y_pred = []
        y_test = []
        
        for i in range(window, len(X)):
            # éå»næœŸé–“ã®å¹³å‡ã‚’äºˆæ¸¬å€¤ã¨ã™ã‚‹
            pred = np.mean(y.iloc[i-window:i])
            y_pred.append(pred)
            y_test.append(y.iloc[i])
        
        y_pred = np.array(y_pred)
        y_test = np.array(y_test)
        
        # è©•ä¾¡æŒ‡æ¨™
        mse = np.mean((y_test - y_pred) ** 2)
        mae = np.mean(np.abs(y_test - y_pred))
        
        self.logger.info(f"MSE: {mse:.4f}")
        self.logger.info(f"MAE: {mae:.4f}")
        
        return {
            'model_type': 'SimpleMovingAverage',
            'mse': mse,
            'mae': mae,
            'test_predictions': y_pred,
            'test_actual': y_test
        }

    def predict_next_price(self, symbol: str, periods: int = 5) -> list:
        """æ¬¡ã®æœŸé–“ã®ä¾¡æ ¼ã‚’äºˆæ¸¬"""
        if self.advanced_model is None:
            self.logger.error("âŒ é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        try:
            # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            conn = sqlite3.connect(self.db_path)
            query = '''
                SELECT datetime, open_price, high_price, low_price, close_price, volume
                FROM chart_data
                WHERE symbol = ? AND timeframe = '5M'
                ORDER BY datetime DESC
                LIMIT 100
            '''
            
            df = pd.read_sql_query(query, conn, params=(symbol,))
            conn.close()
            
            if df.empty:
                return []
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã³æ›¿ãˆ
            df = df.sort_values('datetime').reset_index(drop=True)
            
            # ç‰¹å¾´é‡ã‚’ä½œæˆ
            df = self.create_advanced_features(df)
            
            # æœ€æ–°ã®ç‰¹å¾´é‡ã‚’å–å¾—
            if self.feature_columns:
                X_latest = df[self.feature_columns].tail(1)
                X_latest = X_latest.replace([np.inf, -np.inf], np.nan).fillna(X_latest.median())
                
                # äºˆæ¸¬
                prediction = self.advanced_model.predict(X_latest)[0]
                return [prediction]
            else:
                # ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å ´åˆ
                prediction = df['close_price'].tail(5).mean()
                return [prediction]
                
        except Exception as e:
            self.logger.error(f"ä¾¡æ ¼äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def generate_comparison_report(self, symbol: str, results: dict, y_test: np.ndarray) -> str:
        """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = f"=== {symbol} ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ ===\n\n"
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’æ•´ç†
        model_scores = []
        for model_name, metrics in results.items():
            model_scores.append({
                'model': model_name,
                'mse': metrics['mse'],
                'mae': metrics['mae'],
                'r2': metrics['r2']
            })
        
        # MAEã§ä¸¦ã³æ›¿ãˆï¼ˆä½ã„ã»ã†ãŒè‰¯ã„ï¼‰
        model_scores.sort(key=lambda x: x['mae'])
        
        report += "ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒï¼ˆMAEé †ï¼‰:\n"
        for i, score in enumerate(model_scores, 1):
            report += f"{i}. {score['model']}\n"
            report += f"   MSE: {score['mse']:.4f}\n"
            report += f"   MAE: {score['mae']:.4f}\n"
            report += f"   RÂ²: {score['r2']:.4f}\n\n"
        
        # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«
        best_model = model_scores[0]
        report += f"ğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_model['model']}\n"
        report += f"   ç²¾åº¦è©•ä¾¡: {'é«˜ç²¾åº¦' if best_model['mae'] < 10 else 'ä¸­ç²¾åº¦' if best_model['mae'] < 50 else 'ä½ç²¾åº¦'}\n\n"
        
        # LightGBMã®çµæœãŒã‚ã‚Œã°ç‰¹åˆ¥ã«è¨˜è¼‰
        if 'LightGBM' in results:
            lgb_metrics = results['LightGBM']
            report += f"ğŸš€ LightGBMæ€§èƒ½:\n"
            report += f"   MSE: {lgb_metrics['mse']:.4f}\n"
            report += f"   MAE: {lgb_metrics['mae']:.4f}\n"
            report += f"   RÂ²: {lgb_metrics['r2']:.4f}\n\n"
        
        return report

    def run_integrated_analysis(self, symbols: List[str]) -> Dict:
        """çµ±åˆåˆ†æã‚’å®Ÿè¡Œï¼ˆæ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰ï¼‰"""
        results = {}
        
        for symbol in symbols:
            self.logger.info(f"\n{'='*50}")
            self.logger.info(f"éŠ˜æŸ„: {symbol}")
            self.logger.info('='*50)
            
            # é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æº–å‚™
            X, y, df, feature_cols = self.prepare_advanced_data(symbol)
            
            if X is None:
                continue
            
            # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
            comparison_results, y_test = self.train_advanced_model(X, y, model_type='comparison')
            
            # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_comparison_report(symbol, comparison_results, y_test)
            self.logger.info(report)
            
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            try:
                with open(f'{symbol}_comparison_report.txt', 'w', encoding='utf-8') as f:
                    f.write(report)
                self.logger.info(f"ğŸ“Š æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {symbol}_comparison_report.txt")
            except Exception as e:
                self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            
            results[symbol] = {
                'comparison_results': comparison_results,
                'y_test': y_test,
                'report': report
            }
        
        return results

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    ml_models = MLTradingModels()
    
    # ã‚µãƒ³ãƒ—ãƒ«éŠ˜æŸ„ã§è¨“ç·´
    symbols = ['7203', '6758', '8306', '9984', '6861']  # yfinanceãƒ†ã‚¹ãƒˆã§ä½¿ç”¨ã—ãŸéŠ˜æŸ„
    
    print("=== yfinanceãƒ‡ãƒ¼ã‚¿åé›† ===")
    # yfinanceãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    if ml_models.collect_yfinance_data(symbols, days=5):
        print("âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
    else:
        print("âŒ ãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—")
        exit(1)
    
    print("\n=== å¾“æ¥ã®MLäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´ ===")
    # å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    if ml_models.train_hourly_model(symbols):
        print("âœ… 1æ™‚é–“äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
    
    if ml_models.train_minute_model(symbols):
        print("âœ… 5åˆ†è¶³äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
    
    print("\n=== é«˜åº¦ãªçµ±åˆåˆ†æï¼ˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼‰===")
    # çµ±åˆåˆ†æå®Ÿè¡Œ
    results = ml_models.run_integrated_analysis(symbols)
    
    print("\n=== ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯äºˆæ¸¬ãƒ†ã‚¹ãƒˆ ===")
    # äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
    current_time = datetime.now()
    
    for symbol in symbols:
        result = ml_models.fact_check_predictions(symbol, current_time)
        
        print(f"\n{symbol} ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ:")
        print(f"å–å¼•å®Ÿè¡Œ: {result['should_trade']}")
        print(f"æ–¹å‘: {result['direction']}")
        print(f"ä¿¡é ¼åº¦: {result['confidence']:.3f}")
        print(f"1æ™‚é–“äºˆæ¸¬: {result['hourly_prediction']}")
        print(f"5åˆ†è¶³äºˆæ¸¬: {result['minute_prediction']}")
    
    print("\n=== çµ±åˆå®Œäº† ===")
    print("âœ… å…¨ã¦ã®æ©Ÿèƒ½ãŒçµ±åˆã•ã‚Œã¾ã—ãŸ")
    print("ğŸ“Š æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
    print("ğŸ¤– è¤‡æ•°ã®MLäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒæ¯”è¼ƒã•ã‚Œã¾ã—ãŸ")
    if lightgbm_available:
        print("ğŸš€ LightGBMã‚‚æ¯”è¼ƒã«å«ã¾ã‚Œã¦ã„ã¾ã™")
    else:
        print("âš ï¸  LightGBMã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ (pip install lightgbm ã§è¿½åŠ å¯èƒ½)")
