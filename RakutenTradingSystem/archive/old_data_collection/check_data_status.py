#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿åé›†çŠ¶æ³ã‚’è©³ç´°ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import sqlite3
import os
from datetime import datetime
from collections import defaultdict
import json

def check_database_status(db_path):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯"""
    if not os.path.exists(db_path):
        return None
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
    file_size = os.path.getsize(db_path) / 1024 / 1024  # MB
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = [row[0] for row in cursor.fetchall()]
    
    result = {
        'path': db_path,
        'size_mb': round(file_size, 2),
        'tables': tables,
        'table_info': {}
    }
    
    # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®æƒ…å ±
    for table in tables:
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {table}")
            count = cursor.fetchone()[0]
            result['table_info'][table] = {'count': count}
        except:
            pass
    
    conn.close()
    return result

def analyze_chart_data(db_path='trading_data.db'):
    """chart_dataã®è©³ç´°åˆ†æ"""
    if not os.path.exists(db_path):
        print(f"âŒ {db_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    print("=" * 80)
    print("ğŸ“Š chart_data è©³ç´°åˆ†æ")
    print("=" * 80)
    
    # ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
    cursor.execute("SELECT COUNT(*) FROM chart_data")
    total_records = cursor.fetchone()[0]
    print(f"\nç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_records:,}")
    
    # éŠ˜æŸ„ä¸€è¦§
    cursor.execute("SELECT DISTINCT symbol FROM chart_data ORDER BY symbol")
    symbols = [row[0] for row in cursor.fetchall()]
    print(f"åé›†éŠ˜æŸ„æ•°: {len(symbols)}")
    print(f"éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰: {', '.join(symbols)}")
    
    # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ 
    cursor.execute("SELECT DISTINCT timeframe FROM chart_data")
    timeframes = [row[0] for row in cursor.fetchall()]
    print(f"ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ : {', '.join(timeframes)}")
    
    # ãƒ‡ãƒ¼ã‚¿æœŸé–“
    cursor.execute("SELECT MIN(datetime), MAX(datetime) FROM chart_data")
    min_date, max_date = cursor.fetchone()
    print(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date} ï½ {max_date}")
    
    # éŠ˜æŸ„åˆ¥è©³ç´°
    print("\n" + "-" * 80)
    print("éŠ˜æŸ„åˆ¥ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
    print("-" * 80)
    
    query = """
    SELECT 
        symbol,
        timeframe,
        COUNT(*) as records,
        MIN(datetime) as first_datetime,
        MAX(datetime) as last_datetime,
        COUNT(DISTINCT DATE(datetime)) as trading_days,
        AVG(volume) as avg_volume,
        MAX(high_price) as max_price,
        MIN(low_price) as min_price
    FROM chart_data
    GROUP BY symbol, timeframe
    ORDER BY symbol, timeframe
    """
    
    cursor.execute(query)
    results = cursor.fetchall()
    
    symbol_stats = defaultdict(lambda: {'timeframes': {}, 'total_records': 0})
    
    for row in results:
        symbol, tf, records, first, last, days, avg_vol, max_p, min_p = row
        symbol_stats[symbol]['total_records'] += records
        symbol_stats[symbol]['timeframes'][tf] = {
            'records': records,
            'first': first,
            'last': last,
            'trading_days': days,
            'avg_volume': avg_vol,
            'price_range': (min_p, max_p)
        }
    
    for symbol in sorted(symbol_stats.keys()):
        stats = symbol_stats[symbol]
        print(f"\nã€{symbol}ã€‘")
        print(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats['total_records']:,}")
        
        for tf, tf_stats in stats['timeframes'].items():
            print(f"  - ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ : {tf}")
            print(f"    ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {tf_stats['records']:,}")
            print(f"    å–å¼•æ—¥æ•°: {tf_stats['trading_days']}æ—¥")
            print(f"    æœŸé–“: {tf_stats['first']} ï½ {tf_stats['last']}")
            if tf_stats['avg_volume']:
                print(f"    å¹³å‡å‡ºæ¥é«˜: {tf_stats['avg_volume']:,.0f}")
            if tf_stats['price_range'][0]:
                print(f"    ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸: {tf_stats['price_range'][0]:,.2f} ï½ {tf_stats['price_range'][1]:,.2f}")
    
    # æ—¥æ¬¡çµ±è¨ˆ
    print("\n" + "-" * 80)
    print("æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
    print("-" * 80)
    
    query = """
    SELECT 
        DATE(datetime) as date,
        COUNT(*) as records,
        COUNT(DISTINCT symbol) as symbols,
        COUNT(DISTINCT timeframe) as timeframes
    FROM chart_data
    GROUP BY DATE(datetime)
    ORDER BY date
    """
    
    cursor.execute(query)
    daily_stats = cursor.fetchall()
    
    print(f"\n{'æ—¥ä»˜':<12} {'ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°':>10} {'éŠ˜æŸ„æ•°':>8} {'TFæ•°':>6}")
    print("-" * 40)
    for date, records, symbols, tfs in daily_stats:
        print(f"{date:<12} {records:>10,} {symbols:>8} {tfs:>6}")
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    print("\n" + "-" * 80)
    print("ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯")
    print("-" * 80)
    
    # NULLå€¤ãƒã‚§ãƒƒã‚¯
    null_checks = [
        ('symbol', 'symbol'),
        ('datetime', 'datetime'),
        ('open_price', 'open_price'),
        ('high_price', 'high_price'),
        ('low_price', 'low_price'),
        ('close_price', 'close_price'),
        ('volume', 'volume')
    ]
    
    print("\nNULLå€¤ãƒã‚§ãƒƒã‚¯:")
    has_nulls = False
    for name, col in null_checks:
        cursor.execute(f"SELECT COUNT(*) FROM chart_data WHERE {col} IS NULL")
        null_count = cursor.fetchone()[0]
        if null_count > 0:
            print(f"  âš ï¸  {name}: {null_count} ä»¶ã®NULL")
            has_nulls = True
    
    if not has_nulls:
        print("  âœ… NULLå€¤ãªã—")
    
    # ä¾¡æ ¼ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    cursor.execute("""
        SELECT COUNT(*) FROM chart_data 
        WHERE high_price < low_price 
           OR high_price < open_price 
           OR high_price < close_price
           OR low_price > open_price
           OR low_price > close_price
    """)
    invalid_prices = cursor.fetchone()[0]
    
    if invalid_prices > 0:
        print(f"  âš ï¸  ä¾¡æ ¼ã®ä¸æ•´åˆ: {invalid_prices} ä»¶")
    else:
        print("  âœ… ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§: æ­£å¸¸")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    cursor.execute("""
        SELECT symbol, datetime, timeframe, COUNT(*) as cnt
        FROM chart_data
        GROUP BY symbol, datetime, timeframe
        HAVING cnt > 1
    """)
    duplicates = cursor.fetchall()
    
    if duplicates:
        print(f"  âš ï¸  é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰: {len(duplicates)} ä»¶")
        for dup in duplicates[:5]:
            print(f"     {dup[0]} {dup[1]} {dup[2]}: {dup[3]} ä»¶")
    else:
        print("  âœ… é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰: ãªã—")
    
    conn.close()

def analyze_fundamental_data(db_path='fundamental_data.db'):
    """ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
    if not os.path.exists(db_path):
        print(f"\nâŒ {db_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ“ˆ fundamental_data åˆ†æ")
    print("=" * 80)
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = [row[0] for row in cursor.fetchall()]
    print(f"\nãƒ†ãƒ¼ãƒ–ãƒ«: {', '.join(tables)}")
    
    for table in tables:
        cursor.execute(f"SELECT COUNT(*) FROM {table}")
        count = cursor.fetchone()[0]
        print(f"  {table}: {count:,} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        
        if count > 0 and table == 'fundamental_data':
            cursor.execute(f"SELECT * FROM {table} LIMIT 3")
            print(f"\n  ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:")
            for row in cursor.fetchall():
                print(f"    {row}")
    
    conn.close()

def check_csv_data(csv_base_path='csv_data'):
    """CSVãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèª"""
    print("\n" + "=" * 80)
    print("ğŸ“ CSV ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯")
    print("=" * 80)
    
    if not os.path.exists(csv_base_path):
        print(f"\nâŒ {csv_base_path} ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return
    
    csv_files = []
    for root, dirs, files in os.walk(csv_base_path):
        for file in files:
            if file.endswith('.csv'):
                full_path = os.path.join(root, file)
                size = os.path.getsize(full_path)
                csv_files.append((full_path, size))
    
    if not csv_files:
        print("\nâŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        print(f"\nè¦‹ã¤ã‹ã£ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«: {len(csv_files)} ä»¶")
        for path, size in csv_files[:10]:
            print(f"  {path}: {size:,} bytes")
        if len(csv_files) > 10:
            print(f"  ... ä»– {len(csv_files) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")

def check_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª"""
    print("\n" + "=" * 80)
    print("âš™ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª")
    print("=" * 80)
    
    config_file = 'config.json'
    if not os.path.exists(config_file):
        print(f"\nâŒ {config_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    print(f"\nã‚·ã‚¹ãƒ†ãƒ è¨­å®š:")
    for key, value in config.get('system_settings', {}).items():
        print(f"  {key}: {value}")
    
    print(f"\nåé›†è¨­å®š:")
    for key, value in config.get('collection_settings', {}).items():
        print(f"  {key}: {value}")

def check_prime_symbols():
    """ç›£è¦–å¯¾è±¡éŠ˜æŸ„ã®ç¢ºèª"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ ç›£è¦–å¯¾è±¡éŠ˜æŸ„")
    print("=" * 80)
    
    symbols_file = 'prime_symbols.csv'
    if not os.path.exists(symbols_file):
        print(f"\nâŒ {symbols_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    with open(symbols_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã
    data_lines = [l for l in lines if l.strip() and not l.startswith('symbol,')]
    
    print(f"\nç›£è¦–å¯¾è±¡éŠ˜æŸ„æ•°: {len(data_lines)}")
    
    # ãƒ‡ã‚¤ãƒˆãƒ¬ãƒ¼ãƒ‰é©åˆéŠ˜æŸ„
    suitable_count = sum(1 for line in data_lines if 'true' in line.lower())
    print(f"ãƒ‡ã‚¤ãƒˆãƒ¬ãƒ¼ãƒ‰é©åˆ: {suitable_count} éŠ˜æŸ„")
    
    # å®Ÿéš›ã«åé›†ã•ã‚Œã¦ã„ã‚‹éŠ˜æŸ„ã¨ã®æ¯”è¼ƒ
    if os.path.exists('trading_data.db'):
        conn = sqlite3.connect('trading_data.db')
        cursor = conn.cursor()
        cursor.execute("SELECT DISTINCT symbol FROM chart_data")
        collected_symbols = set(row[0] for row in cursor.fetchall())
        conn.close()
        
        print(f"å®Ÿéš›ã«åé›†æ¸ˆã¿: {len(collected_symbols)} éŠ˜æŸ„")
        print(f"åé›†ç‡: {len(collected_symbols) / len(data_lines) * 100:.1f}%")
        
        if collected_symbols:
            print(f"\nåé›†æ¸ˆã¿éŠ˜æŸ„: {', '.join(sorted(collected_symbols))}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    os.chdir('/workspaces/kabu/RakutenTradingSystem')
    
    print("=" * 80)
    print("ğŸ” ãƒ‡ãƒ¼ã‚¿åé›†çŠ¶æ³ãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«")
    print("=" * 80)
    print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
    
    # è¨­å®šç¢ºèª
    check_config()
    
    # ç›£è¦–å¯¾è±¡éŠ˜æŸ„
    check_prime_symbols()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹
    print("\n" + "=" * 80)
    print("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
    print("=" * 80)
    
    db_files = [
        'trading_data.db',
        'fundamental_data.db',
        'daily_trading_data.db',
        'core/trading_data.db',
        'core/fundamental_data.db'
    ]
    
    for db_file in db_files:
        if os.path.exists(db_file):
            status = check_database_status(db_file)
            if status:
                print(f"\n{db_file}:")
                print(f"  ã‚µã‚¤ã‚º: {status['size_mb']} MB")
                print(f"  ãƒ†ãƒ¼ãƒ–ãƒ«: {', '.join(status['tables'])}")
                for table, info in status['table_info'].items():
                    print(f"    {table}: {info['count']:,} ãƒ¬ã‚³ãƒ¼ãƒ‰")
    
    # è©³ç´°åˆ†æ
    analyze_chart_data('trading_data.db')
    analyze_fundamental_data('fundamental_data.db')
    check_csv_data('csv_data')
    
    # ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("ğŸ“ ãƒã‚§ãƒƒã‚¯å®Œäº†")
    print("=" * 80)
    print("\nè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã¯ data_collection_check_report.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„")

if __name__ == '__main__':
    main()
