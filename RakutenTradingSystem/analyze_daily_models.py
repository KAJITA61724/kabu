#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥æ¬¡ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ ã®ã‚µãƒãƒªãƒ¼ç¢ºèª
æ¯æ—¥ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’çŠ¶æ³ã¨äºˆæ¸¬æ€§èƒ½ã‚’åˆ†æ
"""
import os
import pickle
from datetime import datetime
import pandas as pd

def analyze_daily_models():
    """ä¿å­˜ã•ã‚ŒãŸæ—¥æ¬¡ãƒ¢ãƒ‡ãƒ«ã®åˆ†æ"""
    models_dir = "daily_models"
    
    if not os.path.exists(models_dir):
        print("ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print("æ—¥æ¬¡ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ  åˆ†æçµæœ")
    print("="*60)
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.pkl')]
    
    # æ—¥ä»˜ã¨ã‚·ãƒ³ãƒœãƒ«åˆ¥ã«æ•´ç†
    model_data = {}
    for file in model_files:
        parts = file.replace('.pkl', '').split('_')
        if len(parts) >= 3:
            symbol = parts[0]
            date_str = parts[-1]
            
            if date_str not in model_data:
                model_data[date_str] = {}
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            try:
                with open(os.path.join(models_dir, file), 'rb') as f:
                    data = pickle.load(f)
                    model_data[date_str][symbol] = data
            except Exception as e:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file} - {e}")
    
    # æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆ
    sorted_dates = sorted(model_data.keys())
    
    print(f"\\nğŸ“Š ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Ÿè¡Œæ—¥æ•°: {len(sorted_dates)}æ—¥")
    print(f"å¯¾è±¡æœŸé–“: {sorted_dates[0]} ï½ {sorted_dates[-1]}")
    
    # å„æ—¥ã®è©³ç´°åˆ†æ
    for date_str in sorted_dates:
        date_obj = datetime.strptime(date_str, '%Y%m%d')
        print(f"\\n{'â”€'*50}")
        print(f"ğŸ“… {date_obj.date()} (Day {sorted_dates.index(date_str)+1})")
        print(f"{'â”€'*50}")
        
        day_data = model_data[date_str]
        
        for symbol, data in day_data.items():
            scores = data['scores']
            data_size = data['data_size']
            model_count = len(data['models'])
            
            print(f"  {symbol}: {model_count}ãƒ¢ãƒ‡ãƒ«, ãƒ‡ãƒ¼ã‚¿æ•°{data_size}")
            
            # å„ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢
            for model_name, score in scores.items():
                status = "ğŸŸ¢" if score > -0.05 else "ğŸŸ¡" if score > -0.1 else "ğŸ”´"
                print(f"    {status} {model_name}: {score:+.3f}")
            
            # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
            best_model = max(scores.items(), key=lambda x: x[1])
            print(f"    ğŸ† Best: {best_model[0]} ({best_model[1]:+.3f})")
    
    # å…¨ä½“çµ±è¨ˆ
    print(f"\\n{'='*60}")
    print("ğŸ“ˆ å…¨æœŸé–“çµ±è¨ˆ")
    print(f"{'='*60}")
    
    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½çµ±è¨ˆ
    all_scores = []
    symbol_stats = {}
    
    for date_str, day_data in model_data.items():
        for symbol, data in day_data.items():
            if symbol not in symbol_stats:
                symbol_stats[symbol] = {'scores': [], 'days': 0}
            
            symbol_stats[symbol]['days'] += 1
            for model_name, score in data['scores'].items():
                all_scores.append(score)
                symbol_stats[symbol]['scores'].append(score)
    
    print(f"ç·ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å›æ•°: {len(all_scores)}")
    print(f"å¹³å‡ã‚¹ã‚³ã‚¢: {sum(all_scores)/len(all_scores):.3f}")
    print(f"æœ€é«˜ã‚¹ã‚³ã‚¢: {max(all_scores):+.3f}")
    print(f"æœ€ä½ã‚¹ã‚³ã‚¢: {min(all_scores):+.3f}")
    
    # éŠ˜æŸ„åˆ¥çµ±è¨ˆ
    print(f"\\nğŸ“Š éŠ˜æŸ„åˆ¥ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
    for symbol, stats in symbol_stats.items():
        avg_score = sum(stats['scores']) / len(stats['scores'])
        best_score = max(stats['scores'])
        print(f"  {symbol}: {stats['days']}æ—¥, å¹³å‡{avg_score:+.3f}, æœ€é«˜{best_score:+.3f}")
    
    # ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã®æœ‰åŠ¹æ€§ç¢ºèª
    print(f"\\nğŸ” ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã®æœ‰åŠ¹æ€§:")
    print("âœ… æ¯æ—¥å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’")
    print("âœ… RandomForest, LinearRegression, LightGBM ã®3ãƒ¢ãƒ‡ãƒ«")
    print("âœ… ã‚¹ã‚³ã‚¢é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬")
    print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ°¸ç¶šåŒ–ä¿å­˜")
    print("âœ… å„æ—¥ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è¨˜éŒ²")

def check_model_evolution():
    """ãƒ¢ãƒ‡ãƒ«ã®æ—¥æ¬¡é€²åŒ–ã‚’ç¢ºèª"""
    models_dir = "daily_models"
    
    # ç‰¹å®šéŠ˜æŸ„ã®é€²åŒ–ã‚’è¿½è·¡
    symbol = "7203"
    dates = ["20250715", "20250716", "20250717", "20250718"]
    
    print(f"\\nğŸ”¬ {symbol} ãƒ¢ãƒ‡ãƒ«é€²åŒ–åˆ†æ:")
    print("="*40)
    
    evolution_data = []
    
    for date in dates:
        filename = f"{symbol}_models_{date}.pkl"
        filepath = os.path.join(models_dir, filename)
        
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
                
            best_score = max(data['scores'].values())
            best_model = max(data['scores'].items(), key=lambda x: x[1])[0]
            
            evolution_data.append({
                'date': date,
                'best_score': best_score,
                'best_model': best_model,
                'data_size': data['data_size']
            })
            
            date_obj = datetime.strptime(date, '%Y%m%d')
            print(f"  {date_obj.date()}: {best_model} {best_score:+.3f} (ãƒ‡ãƒ¼ã‚¿{data['data_size']})")
    
    if len(evolution_data) > 1:
        score_change = evolution_data[-1]['best_score'] - evolution_data[0]['best_score']
        print(f"\\nğŸ“ˆ é€²åŒ–çµæœ: {score_change:+.3f} ({'æ”¹å–„' if score_change > 0 else 'æ‚ªåŒ–'})")

if __name__ == "__main__":
    analyze_daily_models()
    check_model_evolution()
    
    print(f"\\n{'='*60}")
    print("ğŸ¯ çµè«–: äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¯æ¯æ—¥å‰æ—¥ãƒ‡ãƒ¼ã‚¿ã§ä½œã‚Šç›´ã—ã¦ã„ã‚‹!")
    print("ğŸ“ è¨¼æ‹ : daily_models/ ã«æ—¥ä»˜åˆ¥ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æ¸ˆã¿")
    print("ğŸ“Š å„æ—¥ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãŒãƒ¬ãƒãƒ¼ãƒˆã«è¨˜éŒ²æ¸ˆã¿")
    print(f"{'='*60}")
