"""
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ« - å®Œå…¨çµ±åˆç‰ˆ
- 1æ™‚é–“ç·šå½¢äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
- 5åˆ†è¶³ä¸Šä¸‹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
- ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
- ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æçµ±åˆ
- é«˜åº¦ãªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒæ©Ÿèƒ½
"""

import pandas as pd
import numpy as np
import sqlite3
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score
import joblib
from pathlib import Path
import sys
import os

# yfinanceãƒ‡ãƒ¼ã‚¿åé›†ã¨ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿åé›†å™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from fundamental_data_collector import FundamentalDataCollector
except ImportError:
    FundamentalDataCollector = None

# yfinanceã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import yfinance as yf
    yfinance_available = True
except ImportError:
    yfinance_available = False

# scikit-learnã®è¿½åŠ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    sklearn_available = True
except ImportError:
    sklearn_available = False

class MLTradingModels:
    """æ©Ÿæ¢°å­¦ç¿’å–å¼•ãƒ¢ãƒ‡ãƒ« - å®Œå…¨çµ±åˆç‰ˆ"""
    
    def __init__(self, db_path: str = "trading_data.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self.hourly_model = LinearRegression()
        self.minute_model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.scaler = StandardScaler()
        
        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿åé›†å™¨
        if FundamentalDataCollector:
            self.fundamental_collector = FundamentalDataCollector()
        else:
            self.fundamental_collector = None
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‘ã‚¹
        self.model_dir = Path("models")
        self.model_dir.mkdir(exist_ok=True)
        
        # äºˆæ¸¬ç²¾åº¦è¿½è·¡
        self.prediction_history = []
        
        # çµ±åˆæ©Ÿèƒ½ç”¨ã®è¿½åŠ ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
        self.feature_columns = None
        self.advanced_model = None
        
    def collect_yfinance_data(self, symbols: List[str], days: int = 5) -> bool:
        """yfinanceã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        if not yfinance_available:
            self.logger.error("yfinanceãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS chart_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    datetime TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    open_price REAL NOT NULL,
                    high_price REAL NOT NULL,
                    low_price REAL NOT NULL,
                    close_price REAL NOT NULL,
                    volume INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(symbol, datetime, timeframe)
                )
            ''')
            
            success_count = 0
            total_data = 0
            
            for symbol in symbols:
                try:
                    # yfinanceã§ãƒ‡ãƒ¼ã‚¿å–å¾—
                    yahoo_symbol = f"{symbol}.T"
                    end_date = datetime.now()
                    start_date = end_date - timedelta(days=days)
                    
                    ticker = yf.Ticker(yahoo_symbol)
                    data = ticker.history(start=start_date, end=end_date, interval="5m")
                    
                    if data.empty:
                        self.logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yahoo_symbol}")
                        continue
                    
                    # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
                    df = data.reset_index()
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                    for _, row in df.iterrows():
                        cursor.execute('''
                            INSERT OR REPLACE INTO chart_data 
                            (symbol, datetime, timeframe, open_price, high_price, low_price, close_price, volume)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            symbol,
                            row['Datetime'].strftime('%Y-%m-%d %H:%M:%S'),
                            '5m',
                            row['Open'],
                            row['High'],
                            row['Low'],
                            row['Close'],
                            int(row['Volume'])
                        ))
                    
                    success_count += 1
                    total_data += len(df)
                    self.logger.info(f"âœ… {symbol}: {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜")
                    
                except Exception as e:
                    self.logger.error(f"âŒ {symbol}ã®ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            conn.commit()
            conn.close()
            
            self.logger.info(f"ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {success_count}/{len(symbols)}éŠ˜æŸ„, {total_data}ä»¶")
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def create_advanced_features(self, df: pd.DataFrame, symbol: str = None) -> pd.DataFrame:
        """é«˜åº¦ãªç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿çµ±åˆï¼‰"""
        if df.empty or len(df) < 10:
            return pd.DataFrame()
        
        df = df.copy()
        
        # åŸºæœ¬çš„ãªç‰¹å¾´é‡
        df['price_change'] = df['close_price'].pct_change()
        df['high_low_ratio'] = df['high_price'] / df['low_price']
        df['open_close_ratio'] = df['open_price'] / df['close_price']
        df['volume_price_ratio'] = df['volume'] / df['close_price']
        
        # ç§»å‹•å¹³å‡
        df['sma_5'] = df['close_price'].rolling(window=5).mean()
        df['sma_10'] = df['close_price'].rolling(window=10).mean()
        df['sma_ratio'] = df['close_price'] / df['sma_5']
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        df['volatility_5'] = df['close_price'].rolling(window=5).std()
        df['volatility_10'] = df['close_price'].rolling(window=10).std()
        
        # å‡ºæ¥é«˜ç³»
        df['volume_sma_5'] = df['volume'].rolling(window=5).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma_5']
        
        # RSIï¼ˆç°¡æ˜“ç‰ˆï¼‰
        delta = df['close_price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # ãƒ©ã‚°ç‰¹å¾´é‡ï¼ˆéå»ã®å€¤ï¼‰
        for lag in [1, 2, 3, 5]:
            df[f'close_lag_{lag}'] = df['close_price'].shift(lag)
            df[f'volume_lag_{lag}'] = df['volume'].shift(lag)
            df[f'change_lag_{lag}'] = df['price_change'].shift(lag)
        
        # æ™‚é–“ç³»ç‰¹å¾´é‡
        df['hour'] = pd.to_datetime(df['datetime']).dt.hour
        df['minute'] = pd.to_datetime(df['datetime']).dt.minute
        df['time_of_day'] = df['hour'] * 60 + df['minute']
        
        # ===== ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡ã®è¿½åŠ  =====
        if symbol and self.fundamental_collector:
            try:
                # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆDBå„ªå…ˆã€ãªã‘ã‚Œã°yfinanceï¼‰
                fundamental_data = self.fundamental_collector.get_fundamental_data_from_db(symbol)
                if not fundamental_data:
                    fundamental_data = self.fundamental_collector.get_fundamental_data_yfinance(symbol)
                
                if fundamental_data:
                    # è²¡å‹™æŒ‡æ¨™ã‚’ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ 
                    df['per'] = getattr(fundamental_data, 'per', 0)  # PER
                    df['pbr'] = getattr(fundamental_data, 'pbr', 0)  # PBR
                    df['dividend_yield'] = getattr(fundamental_data, 'dividend_yield', 0)  # é…å½“åˆ©å›ã‚Š
                    df['roe'] = getattr(fundamental_data, 'roe', 0)  # ROE
                    df['roa'] = getattr(fundamental_data, 'roa', 0)  # ROA
                    df['market_cap'] = getattr(fundamental_data, 'market_cap', 0)  # æ™‚ä¾¡ç·é¡
                    df['eps'] = getattr(fundamental_data, 'eps', 0)  # EPS
                    df['bps'] = getattr(fundamental_data, 'bps', 0)  # BPS
                    
                    # æ¥­ç¸¾ãƒ‡ãƒ¼ã‚¿
                    df['revenue_growth'] = getattr(fundamental_data, 'revenue_growth', 0)  # å£²ä¸Šæˆé•·ç‡
                    df['profit_growth'] = getattr(fundamental_data, 'profit_growth', 0)  # åˆ©ç›Šæˆé•·ç‡
                    df['debt_ratio'] = getattr(fundamental_data, 'debt_ratio', 0)  # è² å‚µæ¯”ç‡
                    
                    # ã‚»ã‚¯ã‚¿ãƒ¼é–¢é€£
                    df['sector_avg_per'] = getattr(fundamental_data, 'sector_avg_per', 0)  # ã‚»ã‚¯ã‚¿ãƒ¼å¹³å‡PER
                    df['per_vs_sector'] = df['per'] / (df['sector_avg_per'] + 0.001)  # PERå¯¾ã‚»ã‚¯ã‚¿ãƒ¼æ¯”
                    
                    self.logger.info(f"âœ… {symbol}: ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡ã‚’è¿½åŠ ")
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
                    fundamental_features = [
                        'per', 'pbr', 'dividend_yield', 'roe', 'roa', 'market_cap', 
                        'eps', 'bps', 'revenue_growth', 'profit_growth', 'debt_ratio',
                        'sector_avg_per', 'per_vs_sector'
                    ]
                    for feature in fundamental_features:
                        df[feature] = 0
                    
                    self.logger.warning(f"âš ï¸ {symbol}: ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¼ãƒ­ã§åŸ‹ã‚ã¾ã—ãŸï¼‰")
                    
            except Exception as e:
                self.logger.error(f"âŒ ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
                fundamental_features = [
                    'per', 'pbr', 'dividend_yield', 'roe', 'roa', 'market_cap', 
                    'eps', 'bps', 'revenue_growth', 'profit_growth', 'debt_ratio',
                    'sector_avg_per', 'per_vs_sector'
                ]
                for feature in fundamental_features:
                    df[feature] = 0
        else:
            # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿åé›†å™¨ãŒãªã„å ´åˆã¯ã‚¼ãƒ­ã§åŸ‹ã‚ã‚‹
            fundamental_features = [
                'per', 'pbr', 'dividend_yield', 'roe', 'roa', 'market_cap', 
                'eps', 'bps', 'revenue_growth', 'profit_growth', 'debt_ratio',
                'sector_avg_per', 'per_vs_sector'
            ]
            for feature in fundamental_features:
                df[feature] = 0
        
        # ç›®æ¨™å¤‰æ•°ï¼ˆæ¬¡ã®æœŸé–“ã®ä¾¡æ ¼ï¼‰
        df['target'] = df['close_price'].shift(-1)
        
        return df

    def prepare_advanced_data(self, symbol: str, period: int = 1000) -> tuple:
        """é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        self.logger.info(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­: {symbol}")
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            # yfinanceãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            query = '''
                SELECT datetime, open_price, high_price, low_price, close_price, volume
                FROM chart_data
                WHERE symbol = ? AND timeframe = '5m'
                ORDER BY datetime DESC
                LIMIT ?
            '''
            
            df = pd.read_sql_query(query, conn, params=(symbol, period))
            conn.close()
            
            if df.empty:
                self.logger.error(f"âŒ {symbol} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None, None, None, None
            
            self.logger.info(f"å–å¾—ãƒ‡ãƒ¼ã‚¿æ•°: {len(df)}ä»¶")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ä¸¦ã³æ›¿ãˆ
            df = df.sort_values('datetime').reset_index(drop=True)
            
            # ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿çµ±åˆï¼‰
            df = self.create_advanced_features(df, symbol)
            
            # ç‰¹å¾´é‡ã®åˆ—ã‚’å®šç¾©ï¼ˆãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡ã‚’å«ã‚€ï¼‰
            feature_cols = [
                # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™
                'price_change', 'high_low_ratio', 'open_close_ratio', 'volume_price_ratio',
                'sma_ratio', 'volatility_5', 'volatility_10', 'volume_ratio', 'rsi',
                'close_lag_1', 'close_lag_2', 'close_lag_3', 'close_lag_5',
                'volume_lag_1', 'volume_lag_2', 'volume_lag_3', 'volume_lag_5',
                'change_lag_1', 'change_lag_2', 'change_lag_3', 'change_lag_5',
                'hour', 'minute', 'time_of_day',
                
                # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºæŒ‡æ¨™
                'per', 'pbr', 'dividend_yield', 'roe', 'roa', 'market_cap',
                'eps', 'bps', 'revenue_growth', 'profit_growth', 'debt_ratio',
                'sector_avg_per', 'per_vs_sector'
            ]
            
            # æ¬ æå€¤ã‚’å‰Šé™¤
            df = df.dropna()
            
            if len(df) < 50:
                self.logger.error(f"âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({len(df)}ä»¶)")
                return None, None, None, None
            
            # ç‰¹å¾´é‡ã¨ç›®æ¨™å¤‰æ•°ã‚’åˆ†é›¢
            X = df[feature_cols].copy()
            y = df['target'].copy()
            
            # NaNã‚„ç„¡é™å¤§ã®å€¤ã‚’å‡¦ç†
            X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())
            
            self.logger.info(f"ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
            self.logger.info(f"æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")
            
            self.feature_columns = feature_cols
            
            return X, y, df, feature_cols
            
        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return None, None, None, None

    def train_advanced_model(self, X, y, model_type='advanced'):
        """é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        if sklearn_available and model_type == 'advanced':
            return self._train_sklearn_model(X, y)
        else:
            return self._train_simple_model(X, y)
    
    def _train_sklearn_model(self, X, y):
        """scikit-learnã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        self.logger.info("é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ï¼ˆRandom Forestï¼‰ã‚’è¨“ç·´ä¸­...")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=False
        )
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.advanced_model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.advanced_model.fit(X_train_scaled, y_train)
        
        # äºˆæ¸¬
        y_pred = self.advanced_model.predict(X_test_scaled)
        
        # è©•ä¾¡æŒ‡æ¨™
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        self.logger.info(f"MSE: {mse:.4f}")
        self.logger.info(f"RÂ²: {r2:.4f}")
        self.logger.info(f"MAE: {mae:.4f}")
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        feature_importance = None
        if self.feature_columns:
            feature_importance = pd.DataFrame({
                'feature': self.feature_columns,
                'importance': self.advanced_model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            self.logger.info("\nä¸Šä½10ã®é‡è¦ãªç‰¹å¾´é‡:")
            for _, row in feature_importance.head(10).iterrows():
                self.logger.info(f"  {row['feature']}: {row['importance']:.4f}")
        
        return {
            'model_type': 'RandomForest',
            'mse': mse,
            'r2': r2,
            'mae': mae,
            'feature_importance': feature_importance,
            'test_predictions': y_pred,
            'test_actual': y_test.values,
            'scaler': scaler
        }
    
    def _train_simple_model(self, X, y):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        self.logger.info("ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ï¼ˆç§»å‹•å¹³å‡ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’è¨“ç·´ä¸­...")
        
        # å˜ç´”ãªç§»å‹•å¹³å‡ãƒ¢ãƒ‡ãƒ«
        window = 5
        y_pred = []
        y_test = []
        
        for i in range(window, len(X)):
            # éå»næœŸé–“ã®å¹³å‡ã‚’äºˆæ¸¬å€¤ã¨ã™ã‚‹
            pred = np.mean(y.iloc[i-window:i])
            y_pred.append(pred)
            y_test.append(y.iloc[i])
        
        y_pred = np.array(y_pred)
        y_test = np.array(y_test)
        
        # è©•ä¾¡æŒ‡æ¨™
        mse = np.mean((y_test - y_pred) ** 2)
        mae = np.mean(np.abs(y_test - y_pred))
        
        self.logger.info(f"MSE: {mse:.4f}")
        self.logger.info(f"MAE: {mae:.4f}")
        
        return {
            'model_type': 'SimpleMovingAverage',
            'mse': mse,
            'mae': mae,
            'test_predictions': y_pred,
            'test_actual': y_test
        }

    def run_integrated_analysis(self, symbols: List[str]) -> Dict:
        """çµ±åˆåˆ†æã‚’å®Ÿè¡Œ"""
        results = {}
        
        for symbol in symbols:
            self.logger.info(f"\n{'='*50}")
            self.logger.info(f"éŠ˜æŸ„: {symbol}")
            self.logger.info('='*50)
            
            # é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æº–å‚™
            X, y, df, feature_cols = self.prepare_advanced_data(symbol)
            
            if X is None:
                continue
            
            # é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model_type = 'advanced' if sklearn_available else 'simple'
            model_results = self.train_advanced_model(X, y, model_type)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_prediction_report(symbol, model_results)
            self.logger.info(report)
            
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            try:
                with open(f'{symbol}_prediction_report.txt', 'w', encoding='utf-8') as f:
                    f.write(report)
                self.logger.info(f"ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {symbol}_prediction_report.txt")
            except Exception as e:
                self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            
            results[symbol] = {
                'model_results': model_results,
                'report': report
            }
        
        return results

    def generate_prediction_report(self, symbol: str, results: dict) -> str:
        """äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = f"=== {symbol} äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ ===\n\n"
        
        report += f"ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {results['model_type']}\n"
        report += f"MSE: {results['mse']:.4f}\n"
        report += f"MAE: {results['mae']:.4f}\n"
        
        if 'r2' in results:
            report += f"RÂ²: {results['r2']:.4f}\n"
        
        # äºˆæ¸¬ç²¾åº¦ã®è©•ä¾¡
        if results['mae'] < 10:
            accuracy = "é«˜ç²¾åº¦"
        elif results['mae'] < 50:
            accuracy = "ä¸­ç²¾åº¦"
        else:
            accuracy = "ä½ç²¾åº¦"
        
        report += f"äºˆæ¸¬ç²¾åº¦: {accuracy}\n\n"
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        if results.get('feature_importance') is not None:
            report += "ä¸Šä½5ã¤ã®é‡è¦ãªç‰¹å¾´é‡:\n"
            for _, row in results['feature_importance'].head(5).iterrows():
                report += f"  {row['feature']}: {row['importance']:.4f}\n"
        
        return report

    def compare_models(self, symbols: List[str]) -> Dict:
        """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ"""
        comparison_results = {}
        
        for symbol in symbols:
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ: {symbol}")
            self.logger.info('='*60)
            
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            X, y, df, feature_cols = self.prepare_advanced_data(symbol)
            
            if X is None:
                continue
            
            # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã§è¨“ç·´ãƒ»æ¯”è¼ƒ
            model_results = {}
            
            # 1. Random Forest
            rf_results = self.train_advanced_model(X, y, 'advanced')
            model_results['RandomForest'] = rf_results
            
            # 2. ç§»å‹•å¹³å‡ãƒ¢ãƒ‡ãƒ«
            simple_results = self.train_advanced_model(X, y, 'simple')
            model_results['SimpleMovingAverage'] = simple_results
            
            # 3. ç·šå½¢å›å¸°
            lr_model = LinearRegression()
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, shuffle=False
            )
            
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            lr_model.fit(X_train_scaled, y_train)
            y_pred_lr = lr_model.predict(X_test_scaled)
            
            lr_results = {
                'model_type': 'LinearRegression',
                'mse': mean_squared_error(y_test, y_pred_lr),
                'mae': mean_absolute_error(y_test, y_pred_lr),
                'r2': r2_score(y_test, y_pred_lr),
                'test_predictions': y_pred_lr,
                'test_actual': y_test.values
            }
            model_results['LinearRegression'] = lr_results
            
            # çµæœæ¯”è¼ƒ
            comparison_results[symbol] = model_results
            
            # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self.generate_comparison_report(symbol, model_results)
        
        return comparison_results

    def generate_comparison_report(self, symbol: str, model_results: Dict):
        """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = f"=== {symbol} ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ ===\n\n"
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ã¾ã¨ã‚ã‚‹
        performance_data = []
        for model_name, results in model_results.items():
            performance_data.append({
                'model': model_name,
                'mse': results['mse'],
                'mae': results['mae'],
                'r2': results.get('r2', 0)
            })
        
        # æ€§èƒ½é †ã«ã‚½ãƒ¼ãƒˆï¼ˆMSEãŒå°ã•ã„é †ï¼‰
        performance_data.sort(key=lambda x: x['mse'])
        
        report += "ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆMSEé †ï¼‰:\n"
        for i, perf in enumerate(performance_data, 1):
            report += f"{i}. {perf['model']}\n"
            report += f"   MSE: {perf['mse']:.4f}\n"
            report += f"   MAE: {perf['mae']:.4f}\n"
            report += f"   RÂ²: {perf['r2']:.4f}\n\n"
        
        # æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«
        best_model = performance_data[0]
        report += f"æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_model['model']}\n"
        report += f"MSE: {best_model['mse']:.4f}\n"
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        try:
            with open(f'{symbol}_comparison_report.txt', 'w', encoding='utf-8') as f:
                f.write(report)
            self.logger.info(f"ğŸ“Š æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {symbol}_comparison_report.txt")
        except Exception as e:
            self.logger.error(f"æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.logger.info(f"\n{report}")

    # ===== æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ã®ãŸã‚ã®è¿½åŠ æ©Ÿèƒ½ =====
    
    def prepare_features(self, symbol: str, current_time: datetime):
        """ç‰¹å¾´é‡æº–å‚™ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ç”¨ï¼‰"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            query = '''
                SELECT datetime, open_price, high_price, low_price, close_price, volume
                FROM chart_data
                WHERE symbol = ? AND timeframe = '5m'
                AND datetime <= ?
                ORDER BY datetime DESC
                LIMIT 50
            '''
            
            df = pd.read_sql_query(query, conn, params=(symbol, current_time.strftime('%Y-%m-%d %H:%M:%S')))
            conn.close()
            
            if len(df) < 10:
                return None
            
            # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’ä½œæˆ
            df['price_change'] = df['close_price'].pct_change()
            df['volume_ratio'] = df['volume'] / df['volume'].rolling(5).mean()
            df['sma_5'] = df['close_price'].rolling(5).mean()
            df['volatility'] = df['close_price'].rolling(5).std()
            
            # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡ã‚’è¿½åŠ 
            fundamental_features = [0, 0, 0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            if self.fundamental_collector:
                try:
                    fundamental_data = self.fundamental_collector.get_fundamental_data_from_db(symbol)
                    if not fundamental_data:
                        fundamental_data = self.fundamental_collector.get_fundamental_data_yfinance(symbol)
                    
                    if fundamental_data:
                        fundamental_features = [
                            getattr(fundamental_data, 'per', 0),
                            getattr(fundamental_data, 'pbr', 0),
                            getattr(fundamental_data, 'roe', 0)
                        ]
                except Exception as e:
                    self.logger.warning(f"ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ç‰¹å¾´é‡ã¨ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºç‰¹å¾´é‡ã‚’çµåˆ
            technical_features = df[['price_change', 'volume_ratio', 'volatility']].dropna().iloc[-1:].values
            if len(technical_features) > 0:
                # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ« + ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã‚’çµåˆ
                combined_features = np.concatenate([technical_features[0], fundamental_features])
                return combined_features.reshape(1, -1)
            else:
                return None
            
        except Exception as e:
            self.logger.error(f"ç‰¹å¾´é‡æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict_hourly_trend(self, symbol: str, current_time: datetime) -> Optional[float]:
        """1æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ç”¨ï¼‰"""
        try:
            features = self.prepare_features(symbol, current_time)
            if features is None:
                return None
            
            # ç°¡æ˜“çš„ãªç·šå½¢å›å¸°äºˆæ¸¬
            if not hasattr(self.hourly_model, 'predict'):
                self.hourly_model = LinearRegression()
                # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§åˆæœŸåŒ–ï¼ˆ6ç‰¹å¾´é‡ï¼šãƒ†ã‚¯ãƒ‹ã‚«ãƒ«3å€‹ + ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º3å€‹ï¼‰
                dummy_X = np.random.random((10, 6))
                dummy_y = np.random.random(10)
                self.hourly_model.fit(dummy_X, dummy_y)
            
            prediction = self.hourly_model.predict(features.reshape(1, -1))[0]
            return prediction
            
        except Exception as e:
            self.logger.error(f"1æ™‚é–“äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def predict_minute_direction(self, symbol: str, current_time: datetime) -> Optional[Tuple[int, float]]:
        """5åˆ†è¶³æ–¹å‘äºˆæ¸¬ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ç”¨ï¼‰"""
        try:
            features = self.prepare_features(symbol, current_time)
            if features is None:
                return None
            
            # ç°¡æ˜“çš„ãªåˆ†é¡äºˆæ¸¬
            if not hasattr(self.minute_model, 'predict'):
                self.minute_model = RandomForestClassifier(n_estimators=100, random_state=42)
                # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§åˆæœŸåŒ–ï¼ˆ6ç‰¹å¾´é‡ï¼šãƒ†ã‚¯ãƒ‹ã‚«ãƒ«3å€‹ + ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚º3å€‹ï¼‰
                dummy_X = np.random.random((10, 6))
                dummy_y = np.random.randint(0, 2, 10)
                self.minute_model.fit(dummy_X, dummy_y)
            
            prediction = self.minute_model.predict(features.reshape(1, -1))[0]
            probabilities = self.minute_model.predict_proba(features.reshape(1, -1))[0]
            confidence = max(probabilities)
            
            return prediction, confidence
            
        except Exception as e:
            self.logger.error(f"5åˆ†è¶³äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def fact_check_predictions(self, symbol: str, current_time: datetime) -> Dict:
        """ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ç”¨ï¼‰"""
        result = {
            'should_trade': False,
            'direction': None,
            'confidence': 0.0,
            'hourly_prediction': None,
            'minute_prediction': None,
            'minute_confidence': 0.0
        }
        
        try:
            # 1æ™‚é–“äºˆæ¸¬
            hourly_pred = self.predict_hourly_trend(symbol, current_time)
            if hourly_pred is None:
                return result
            
            # 5åˆ†è¶³äºˆæ¸¬
            minute_result = self.predict_minute_direction(symbol, current_time)
            if minute_result is None:
                return result
            
            minute_pred, minute_conf = minute_result
            
            # æ–¹å‘ã®ä¸€è‡´ãƒã‚§ãƒƒã‚¯
            hourly_direction = 1 if hourly_pred > 0 else 0
            directions_match = hourly_direction == minute_pred
            
            # 5åˆ†è¶³ã®ä¿¡é ¼åº¦ãŒ80%ä»¥ä¸Šã‹ãƒã‚§ãƒƒã‚¯
            high_confidence = minute_conf >= 0.8
            
            result.update({
                'hourly_prediction': hourly_pred,
                'minute_prediction': minute_pred,
                'minute_confidence': minute_conf,
                'should_trade': directions_match and high_confidence,
                'direction': minute_pred if directions_match and high_confidence else None,
                'confidence': minute_conf
            })
            
            self.logger.info(f"ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ - å–å¼•å®Ÿè¡Œ: {result['should_trade']}, æ–¹å‘: {result['direction']}, ä¿¡é ¼åº¦: {result['confidence']:.3f}")
            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
    def hourly_predict(self, symbol: str, current_time: datetime = None) -> Optional[float]:
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ç”¨ã‚¨ã‚¤ãƒªã‚¢ã‚¹"""
        if current_time is None:
            current_time = datetime.now()
        return self.predict_hourly_trend(symbol, current_time)
    
    def minute_predict(self, symbol: str, current_time: datetime = None) -> Optional[Tuple[int, float]]:
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ç”¨ã‚¨ã‚¤ãƒªã‚¢ã‚¹"""
        if current_time is None:
            current_time = datetime.now()
        return self.predict_minute_direction(symbol, current_time)
    
    def fact_check(self, symbol: str, current_time: datetime = None) -> Dict:
        """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ äº’æ›æ€§ç”¨ã‚¨ã‚¤ãƒªã‚¢ã‚¹"""
        if current_time is None:
            current_time = datetime.now()
        return self.fact_check_predictions(symbol, current_time)

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    ml_models = MLTradingModels()
    
    # ã‚µãƒ³ãƒ—ãƒ«éŠ˜æŸ„
    symbols = ['7203', '6758', '8306', '9984', '6861']
    
    print("=== yfinanceãƒ‡ãƒ¼ã‚¿åé›† ===")
    # yfinanceãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    if ml_models.collect_yfinance_data(symbols, days=5):
        print("âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
    else:
        print("âŒ ãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—")
        print("æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ...")
    
    print("\n=== é«˜åº¦ãªçµ±åˆåˆ†æ ===")
    # çµ±åˆåˆ†æå®Ÿè¡Œ
    results = ml_models.run_integrated_analysis(symbols)
    
    print("\n=== è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ ===")
    # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Ÿè¡Œ
    comparison_results = ml_models.compare_models(symbols)
    
    print("\n=== ç·åˆçµæœ ===")
    for symbol in symbols:
        if symbol in comparison_results:
            print(f"\n{symbol}:")
            models = comparison_results[symbol]
            best_model = min(models.items(), key=lambda x: x[1]['mse'])
            print(f"  æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_model[0]}")
            print(f"  MSE: {best_model[1]['mse']:.4f}")
            print(f"  MAE: {best_model[1]['mae']:.4f}")
            if 'r2' in best_model[1]:
                print(f"  RÂ²: {best_model[1]['r2']:.4f}")
    
    print("\n=== çµ±åˆå®Œäº† ===")
    print("âœ… å…¨ã¦ã®æ©Ÿèƒ½ãŒçµ±åˆã•ã‚Œã¾ã—ãŸ")
    print("ğŸ“Š äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
    print("ğŸ¤– è¤‡æ•°MLãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒãŒå®Œäº†ã—ã¾ã—ãŸ")
