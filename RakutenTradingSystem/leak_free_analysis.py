#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒªãƒ¼ã‚¯ãªã—æ—¥æ¬¡ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ ã®åˆ†æã¨æ”¹å–„æ¡ˆ
"""
import os
import pickle
import pandas as pd
import numpy as np
from datetime import datetime

class LeakFreeAnalyzer:
    def __init__(self, models_dir='leak_free_models', reports_dir='leak_free_reports'):
        self.models_dir = models_dir
        self.reports_dir = reports_dir
    
    def analyze_model_performance(self):
        """ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        print("ğŸ“Š ãƒªãƒ¼ã‚¯ãªã—æ—¥æ¬¡ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ  åˆ†æçµæœ")
        print("="*60)
        
        model_files = [f for f in os.listdir(self.models_dir) if f.endswith('.pkl')]
        
        # éŠ˜æŸ„åˆ¥ãƒ»æ—¥ä»˜åˆ¥åˆ†æ
        performance_data = []
        
        for model_file in model_files:
            symbol = model_file.split('_')[0]
            date_str = model_file.split('_')[2].replace('.pkl', '')
            
            try:
                with open(os.path.join(self.models_dir, model_file), 'rb') as f:
                    model_data = pickle.load(f)
                
                scores = model_data['scores']
                best_score = max(scores.values())
                best_model = max(scores.items(), key=lambda x: x[1])[0]
                data_size = model_data['data_size']
                
                performance_data.append({
                    'symbol': symbol,
                    'date': date_str,
                    'best_score': best_score,
                    'best_model': best_model,
                    'data_size': data_size,
                    'rf_score': scores.get('RandomForest', 0),
                    'ridge_score': scores.get('Ridge', 0),
                    'lgb_score': scores.get('LightGBM', 0)
                })
                
            except Exception as e:
                print(f"Error loading {model_file}: {e}")
        
        df = pd.DataFrame(performance_data)
        
        print("\\nğŸ¯ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã‚µãƒãƒªãƒ¼:")
        print(f"ç·ãƒ¢ãƒ‡ãƒ«æ•°: {len(df)}")
        print(f"æ­£ã®RÂ²ã‚¹ã‚³ã‚¢: {len(df[df['best_score'] > 0])}/{len(df)} ({len(df[df['best_score'] > 0])/len(df)*100:.1f}%)")
        
        print("\\nğŸ“ˆ éŠ˜æŸ„åˆ¥ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢:")
        for symbol in df['symbol'].unique():
            symbol_data = df[df['symbol'] == symbol]
            avg_score = symbol_data['best_score'].mean()
            best_day = symbol_data.loc[symbol_data['best_score'].idxmax(), 'date']
            best_score = symbol_data['best_score'].max()
            print(f"  {symbol}: å¹³å‡ {avg_score:.3f}, æœ€é«˜ {best_score:.3f} ({best_day})")
        
        print("\\nğŸ“Š ãƒ¢ãƒ‡ãƒ«åˆ¥å¹³å‡æ€§èƒ½:")
        print(f"  RandomForest: {df['rf_score'].mean():.3f}")
        print(f"  Ridge:        {df['ridge_score'].mean():.3f}")
        print(f"  LightGBM:     {df['lgb_score'].mean():.3f}")
        
        print("\\nğŸ“… æ—¥åˆ¥ãƒ¢ãƒ‡ãƒ«æ”¹å–„:")
        daily_avg = df.groupby('date')['best_score'].mean()
        for date, score in daily_avg.items():
            print(f"  {date}: {score:.3f}")
        
        return df
    
    def suggest_improvements(self):
        """æ”¹å–„ææ¡ˆ"""
        print("\\nğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„ææ¡ˆ:")
        print("="*40)
        
        suggestions = [
            "1. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¼·åŒ–:",
            "   - ã‚ˆã‚Šé•·æœŸé–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™è¿½åŠ ",
            "   - ä»–éŠ˜æŸ„ã¨ã®ç›¸é–¢ç‰¹å¾´é‡",
            "   - ãƒã‚¯ãƒ­çµŒæ¸ˆæŒ‡æ¨™ã®çµ„ã¿è¾¼ã¿",
            "",
            "2. ãƒ¢ãƒ‡ãƒ«æ”¹å–„:",
            "   - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–",
            "   - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿èª¿æ•´",
            "   - æ™‚ç³»åˆ—ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆLSTMç­‰ï¼‰",
            "",
            "3. å–å¼•æˆ¦ç•¥èª¿æ•´:",
            "   - äºˆæ¸¬é–¾å€¤ã®å‹•çš„èª¿æ•´",
            "   - ãƒªã‚¹ã‚¯ç®¡ç†ã®å¼·åŒ–",
            "   - ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚¸ãƒ³ã‚°æœ€é©åŒ–",
            "",
            "4. ãƒ‡ãƒ¼ã‚¿æœŸé–“æ‹¡å¼µ:",
            "   - ã‚ˆã‚Šé•·æœŸé–“ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨",
            "   - å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®æ´»ç”¨",
            "",
            "5. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯¾å¿œ:",
            "   - ãƒ¢ãƒ‡ãƒ«æ›´æ–°é »åº¦ã®èª¿æ•´",
            "   - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã®å°å…¥"
        ]
        
        for suggestion in suggestions:
            print(suggestion)
    
    def performance_summary(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç·è©•"""
        print("\\nğŸ† ã‚·ã‚¹ãƒ†ãƒ è©•ä¾¡:")
        print("="*30)
        
        evaluation = [
            "âœ… æˆåŠŸã—ãŸç‚¹:",
            "  - ãƒªãƒ¼ã‚¯ãªã—ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Ÿç¾",
            "  - yfinanceå®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®å‹•ä½œç¢ºèª",
            "  - 5åˆ†è¶³çµ±ä¸€ã§ã®ä¸€è²«æ€§",
            "  - æ—¥æ¬¡ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚µã‚¤ã‚¯ãƒ«æ§‹ç¯‰",
            "",
            "âš ï¸  èª²é¡Œã¨å¯¾ç­–:",
            "  - è² ã®RÂ²ã‚¹ã‚³ã‚¢ãŒå¤šã„ â†’ ç‰¹å¾´é‡æ”¹å–„ãŒå¿…è¦",
            "  - å–å¼•é »åº¦ãŒä½ã„ â†’ äºˆæ¸¬é–¾å€¤èª¿æ•´",
            "  - çŸ­æœŸãƒ‡ãƒ¼ã‚¿åˆ¶é™ â†’ å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿æ´»ç”¨æ¤œè¨",
            "",
            "ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:",
            "  1. ç‰¹å¾´é‡è¨­è¨ˆã®è¦‹ç›´ã—",
            "  2. ã‚ˆã‚Šé•·æœŸé–“ã§ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ",
            "  3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å–å¼•ã¸ã®é©ç”¨æº–å‚™"
        ]
        
        for item in evaluation:
            print(item)

def main():
    analyzer = LeakFreeAnalyzer()
    
    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ
    df = analyzer.analyze_model_performance()
    
    # æ”¹å–„ææ¡ˆ
    analyzer.suggest_improvements()
    
    # ç·è©•
    analyzer.performance_summary()
    
    print("\\n" + "="*60)
    print("åˆ†æå®Œäº†: ãƒªãƒ¼ã‚¯ãªã—æ—¥æ¬¡ãƒ¢ãƒ‡ãƒ«æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ ")

if __name__ == "__main__":
    main()
