#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‰ã€…æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import sqlite3
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# scikit-learnã¨LightGBMã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    sklearn_available = True
except ImportError:
    sklearn_available = False

try:
    import lightgbm as lgb
    lightgbm_available = True
except ImportError:
    lightgbm_available = False

def load_data_for_evaluation():
    """å‰ã€…æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        conn = sqlite3.connect('trading_data.db')
        
        # å‰ã€…æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— (2025-07-16)
        target_date = '2025-07-16'
        
        query = """
        SELECT symbol, datetime, open_price, high_price, low_price, close_price, volume
        FROM chart_data 
        WHERE datetime LIKE ? 
        ORDER BY symbol, datetime
        """
        
        df = pd.read_sql_query(query, conn, params=(f'{target_date}%',))
        conn.close()
        
        if len(df) == 0:
            print(f"âŒ {target_date}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None
        
        print(f"âœ… {target_date}ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(df)}ä»¶")
        return df
    
    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_features(df):
    """ç‰¹å¾´é‡ã‚’ä½œæˆ"""
    # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values(['symbol', 'datetime'])
    
    feature_data = []
    
    for symbol in df['symbol'].unique():
        symbol_data = df[df['symbol'] == symbol].copy()
        
        # ä¾¡æ ¼é–¢é€£ã®ç‰¹å¾´é‡
        symbol_data['price_change'] = symbol_data['close_price'].pct_change()
        symbol_data['high_low_ratio'] = symbol_data['high_price'] / symbol_data['low_price']
        symbol_data['open_close_ratio'] = symbol_data['open_price'] / symbol_data['close_price']
        symbol_data['volume_price_ratio'] = symbol_data['volume'] / symbol_data['close_price']
        
        # ç§»å‹•å¹³å‡
        symbol_data['sma_5'] = symbol_data['close_price'].rolling(window=5).mean()
        symbol_data['sma_10'] = symbol_data['close_price'].rolling(window=10).mean()
        symbol_data['sma_ratio'] = symbol_data['close_price'] / symbol_data['sma_5']
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        symbol_data['volatility_5'] = symbol_data['close_price'].rolling(window=5).std()
        symbol_data['volatility_10'] = symbol_data['close_price'].rolling(window=10).std()
        
        # å‡ºæ¥é«˜é–¢é€£
        symbol_data['volume_ratio'] = symbol_data['volume'] / symbol_data['volume'].rolling(window=5).mean()
        
        # RSI
        delta = symbol_data['close_price'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        symbol_data['rsi'] = 100 - (100 / (1 + rs))
        
        # ãƒ©ã‚°ç‰¹å¾´é‡
        for lag in [1, 2, 3, 5]:
            symbol_data[f'close_lag_{lag}'] = symbol_data['close_price'].shift(lag)
            symbol_data[f'volume_lag_{lag}'] = symbol_data['volume'].shift(lag)
            symbol_data[f'change_lag_{lag}'] = symbol_data['price_change'].shift(lag)
        
        # æ™‚åˆ»é–¢é€£ã®ç‰¹å¾´é‡
        symbol_data['hour'] = symbol_data['datetime'].dt.hour
        symbol_data['minute'] = symbol_data['datetime'].dt.minute
        symbol_data['time_of_day'] = symbol_data['hour'] * 60 + symbol_data['minute']
        
        # ç›®æ¨™å¤‰æ•°ï¼ˆæ¬¡ã®æ™‚åˆ»ã®ä¾¡æ ¼å¤‰åŒ–ï¼‰
        symbol_data['target'] = symbol_data['close_price'].shift(-1)
        
        feature_data.append(symbol_data)
    
    return pd.concat(feature_data, ignore_index=True)

def evaluate_models(df):
    """ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦è©•ä¾¡"""
    feature_cols = [
        'price_change', 'high_low_ratio', 'open_close_ratio', 'volume_price_ratio',
        'sma_ratio', 'volatility_5', 'volatility_10', 'volume_ratio', 'rsi',
        'close_lag_1', 'close_lag_2', 'close_lag_3', 'close_lag_5',
        'volume_lag_1', 'volume_lag_2', 'volume_lag_3', 'volume_lag_5',
        'change_lag_1', 'change_lag_2', 'change_lag_3', 'change_lag_5',
        'hour', 'minute', 'time_of_day'
    ]
    
    # æ¬ æå€¤ã‚’å‰Šé™¤
    df = df.dropna()
    
    if len(df) < 50:
        print(f"âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({len(df)}ä»¶)")
        return None
    
    # ç‰¹å¾´é‡ã¨ç›®æ¨™å¤‰æ•°ã‚’åˆ†é›¢
    X = df[feature_cols].copy()
    y = df['target'].copy()
    
    # NaNã‚„ç„¡é™å¤§ã®å€¤ã‚’å‡¦ç†
    X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())
    
    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰² (70:30)
    train_size = int(len(X) * 0.7)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    print(f"âœ… ç‰¹å¾´é‡æº–å‚™å®Œäº†: {len(feature_cols)}å€‹ã®ç‰¹å¾´é‡, {len(X_train)}ä»¶ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿, {len(X_test)}ä»¶ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿")
    
    # ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
    models = {}
    
    if sklearn_available:
        models['RandomForest'] = RandomForestRegressor(n_estimators=100, random_state=42)
        models['LinearRegression'] = LinearRegression()
    
    if lightgbm_available:
        models['LightGBM'] = lgb.LGBMRegressor(random_state=42, verbose=-1)
    
    # å˜ç´”ç§»å‹•å¹³å‡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
    models['SimpleMovingAverage'] = None
    
    if not models:
        print("âŒ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # å„ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
    results = {}
    
    for name, model in models.items():
        try:
            if model is None:
                # å˜ç´”ç§»å‹•å¹³å‡ã®å®Ÿè£…
                pred = [np.mean(y_train[-5:]) for _ in range(len(y_test))]
            else:
                model.fit(X_train, y_train)
                pred = model.predict(X_test)
            
            # ç²¾åº¦æŒ‡æ¨™ã®è¨ˆç®—
            mse = mean_squared_error(y_test, pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, pred)
            r2 = r2_score(y_test, pred)
            
            # æ–¹å‘æ€§ã®ç²¾åº¦ï¼ˆä¾¡æ ¼ä¸Šæ˜‡ãƒ»ä¸‹é™ã®äºˆæ¸¬ç²¾åº¦ï¼‰
            actual_direction = np.sign(y_test - X_test['close_lag_1'])
            pred_direction = np.sign(pred - X_test['close_lag_1'])
            direction_accuracy = np.mean(actual_direction == pred_direction)
            
            results[name] = {
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'r2': r2,
                'direction_accuracy': direction_accuracy
            }
            
            print(f"\n{name}:")
            print(f"  MSE: {mse:.4f}")
            print(f"  RMSE: {rmse:.4f}")
            print(f"  MAE: {mae:.4f}")
            print(f"  RÂ²: {r2:.4f}")
            print(f"  æ–¹å‘æ€§ç²¾åº¦: {direction_accuracy:.4f}")
            
        except Exception as e:
            print(f"{name} ã‚¨ãƒ©ãƒ¼: {e}")
            results[name] = {'error': str(e)}
    
    return results

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== å‰ã€…æ—¥ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡ ===")
    print("è©•ä¾¡å¯¾è±¡æ—¥: 2025-07-16")
    print(f"LightGBMåˆ©ç”¨å¯èƒ½: {lightgbm_available}")
    print(f"scikit-learnåˆ©ç”¨å¯èƒ½: {sklearn_available}")
    
    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    df = load_data_for_evaluation()
    if df is None:
        return
    
    # ç‰¹å¾´é‡ã®ä½œæˆ
    print("\n=== ç‰¹å¾´é‡ä½œæˆ ===")
    df_features = create_features(df)
    
    # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
    print("\n=== ãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡ ===")
    results = evaluate_models(df_features)
    
    if results:
        print("\n=== è©•ä¾¡çµæžœã‚µãƒžãƒªãƒ¼ ===")
        print("| ãƒ¢ãƒ‡ãƒ« | RMSE | MAE | RÂ² | æ–¹å‘æ€§ç²¾åº¦ |")
        print("|-------|------|-----|-----|-----------|")
        for name, metrics in results.items():
            if 'error' not in metrics:
                print(f"| {name} | {metrics['rmse']:.4f} | {metrics['mae']:.4f} | {metrics['r2']:.4f} | {metrics['direction_accuracy']:.4f} |")
            else:
                print(f"| {name} | ã‚¨ãƒ©ãƒ¼ | ã‚¨ãƒ©ãƒ¼ | ã‚¨ãƒ©ãƒ¼ | ã‚¨ãƒ©ãƒ¼ |")
        
        # æœ€é©ãƒ¢ãƒ‡ãƒ«ã®é¸æŠž
        valid_results = {k: v for k, v in results.items() if 'error' not in v}
        if valid_results:
            best_model = min(valid_results.items(), key=lambda x: x[1]['rmse'])
            print(f"\nðŸ† æœ€é©ãƒ¢ãƒ‡ãƒ« (RMSEåŸºæº–): {best_model[0]} (RMSE: {best_model[1]['rmse']:.4f})")
            
            best_direction = max(valid_results.items(), key=lambda x: x[1]['direction_accuracy'])
            print(f"ðŸŽ¯ æ–¹å‘æ€§äºˆæ¸¬æœ€å„ªç§€: {best_direction[0]} (ç²¾åº¦: {best_direction[1]['direction_accuracy']:.4f})")

if __name__ == "__main__":
    main()
